{"posts":[{"title":"WRDS 实战 - CCM 的下载与预处理","text":"WRDS 中 CCM 的下载与预处理 0 数据库简介Compustat/CRSP 合并数据库，一般被简称为 CCM，是美国上市公司实证研究中最重要的数据库之一。相当于国内 CSMAR 的资产负债表+利润表+现金流量表+股票信息。 不建议使用单独的 Compustat 数据库，因为信息没有这里的全。 1 获取途径通过 WRDS 进行获取，登录后可以在标签栏快速进入（注意：合并数据在 CRSP 里面而不是 Compustat - Capital IQ 里面 不出意外的话，你可以找到 根据需要选择年度或者季度数据，这里以年度数据作为案例 恭喜你成功进入 CCM 2 数据筛选WRDS 提供了一套相当复杂的数据筛选流程，接下来我一步步解释 2.1 选择日期范围 WRDS 提供了两种日期选择：会计年度（fiscal year）和数据日期（datadate）。 会计年度（fiscal year）和日历年度（calendar year）不一定相同，如果企业选择每年的12月份结束自己的会计年度，那么二者就相同；如果企业打算明年三月、六月等时间出报表的时候再结束，那么而这就不同了。在实证研究中，如果控制年份固定效应，一般是控制会计年度。因为企业可能会更改自己的会计期间结束时间，我们只能保证每个“企业-会计年度”有唯一观测，但是不能保证“企业-日历年度”是唯一的。 数据日期（datadate），简单来说就是报表发布的真实时间（年-月），是常用的 merge variable。事实上，CRSP 的数据也是通过 datadate 合并到每个企业的会计年度上的。 2.2 选择公司代码 上面的 Autocomplete 是询问你希望出现的企业 id 形式，因为国外企业不像国内上市公司，拿着一个股票代码就不会变了，而且几乎每个数据库都会有自己的一套 id，这也就导致了美国/全球公司金融实证的难度比中国公司金融难度更高。 优先级最高的两个 id 是：gvkey：The Global Company Key。Compustat 数据库给每个公司的编码，不会随着时间发生变化cik：Central Index Key。美国证券交易委员会（SEC）分配给向其提交文件的公司和个人的唯一识别号码，用以在SEC数据库中识别和跟踪实体提交的文件，如年报（10-K）和季度报（10-Q）等披露信息。，也不会随着时间变化 其次是：permno：CRSP 数据库给每个证券赋予的编码，也是唯一不会变的。但是为什么优先级不如上面两个呢？因为一家公司可以对应多个证券。permco：CRSP 数据库给每个证券赋予的编码，也是唯一不会变的，和 permno 不同的是，permco 只会唯一对应一家公司。所以，如果要通过 CRSP 的股票日/月数据计算 beta、volatility、return等数据，建议采用 permno 而不是 permco，因为这些数据需要以证券为单位，而 permco 可能对应多个证券，在数据库中同一天/月会出现多个不同的收益率。 再者是：CUSIP：Committee on Uniform Securities Identification Procedures。美国和加拿大金融证券的统一识别码，由 CUSIP Global Services（CGS）负责分配，包含9 位字符（前 6 + 后 2 + 校验位 1）。需要重点注意的是，CUSIP会随着时间发生变化，也就是说一家公司/证券的CUSIP在不同年份可能不同，甚至可能出现不同公司在不同时间使用了同一个CUSIP，所以几乎是没有人采用 CUSIP 进行数据合并。最后是：Ticker：最坑爹的 id，证券在交易所挂牌时使用的交易代码，交易所给投资者提供的证券简称。比如：Apple → AAPL，Microsoft → MSFT，Tesla → TSLA。这玩意也会随着时间发生变化，公司退市再上市后，Ticker可能相同也可能不同，公司改名也会导致Ticker发生变化。比如Facebook变成Meta，代码从 FB 变成 META介绍完后，我们需要选择代码的范围，可以自己导入 txt 确定你的研究代码范围，也可以直接选择整个数据，一般是选择整个数据库。 2.3 变量筛选 这里进行初步的变量筛选。第一条 Consolidation Level 代表选择的报表层级，和 CSMAR 一样，有合并报表（C）、母公司报表（N）等第二条 Industry Format 代表选用的报表格式，大部分公司都选择第一个，金融业的企业可能会选择第二种（注意，这里并没有剔除金融业企业，只是报表格式问题而已）第三条 Data Format 代表选择的报表精简程度，一般选择第一种 STD，标准化的报表第四条 Population Source，D代表样本包含美国和加拿大的上市公司，I代表纳入国际企业第五条 Currency，计价方式，美元或者加元，全选，因为去掉 CAD 会导致加拿大上市公司的观测丢失第六条 Company Status，公司状态，这里全选，不管上市还是退市，先留着最后那个默认就好，其实就是排除掉一些不合理的观测 2.4 变量选择 最上面的三个选项是问你数据来源于哪里？是报表中的数据项目，还是脚注和数据代码？默认就好变量可以一个个挑选了，几百个变量看着太累，我一般是全选下来，双击 All 就全过来了 2.5 导出格式 3 数据下载点击 submit 后，经过漫长等待和网页多次刷新，你会得到以下页面，点击下载即可 4 数据预处理这个数据并不是打开即用的，我们简单测试发现原始数据有以下问题： 首先解决第一个问题，fyear 缺失。观察这 10 个缺失值发现，我们可以直接用 datadate 的年份进行填充 填充后就没有缺失值了 第二个问题，重复问题，我们只要选择最新的观测即可 然后，我们需要把一些能转化成数值的字符数据进行转化 最后，压缩和保存数据（减小内存） 连起来就是 1234567891011121314use &quot;CCM-raw.dta&quot;, clearren GVKEY gvkeyorder gvkey fyear datadatereplace fyear = year(datadate) if fyear == .// 建议使用更稳妥的 replace fyear = cond(fyr &lt;= 6, year(datadate)-1, year(datadate)) if fyear == .// 因为会计结束月份如果在前半年一般是前一年的会计年度gsort gvkey fyear -datadateduplicates drop gvkey fyear, forcedestring *, replacecompresssave &quot;CCM-predo.dta&quot; 5 常见变量 变量名 数据标签 中文含义 gvkey Standard and Poor’s Identifier 标普标识符 cik CIK Number SEC 提供的公司标识 LPERMNO Historical CRSP PERMNO Link to COMPUSTAT Record CRSP 的公司标识（permno） LPERMCO Historical CRSP PERMCO Link to COMPUSTAT Record CRSP 的公司标识（permco），但是一个 permno 可能对应多个 permco cusip CUSIP 美国和加拿大金融证券统一识别码，共 9 位 fyear Data Year - Fiscal 会计年度 fyr Fiscal Year-end Month 会计年度结束月份 datadate Data Date 数据日期，其实就是 日历年 + fyr + 当月最后一天 at Assets - Total 资产总计 lt Liabilities - Total 债务总计 act Current Assets - Total 流动资产 lct Current Liabilities - Total 流动债务 dlc Debt in Current Liabilities - Total 短期负债（流动债务中含息的债务，debt 代表含息的债务，本文使用负债和债务区分二者） dltt Long-Term Debt - Total 长期负债 sale Sales/Turnover (Net) 净销售额（中国语境：营业收入） revt Revenue - Total 营业收入（和 sale 完全一样） oiadp Operating Income After Depreciation 息税前利润（营业利润减去折旧） ebit Earnings Before Interest and Taxes 息税前利润（和 oiadp 完全一致） ib Income Before Extraordinary Items 非常项目前收益（不建议用来计算 ROA，2015年被 US-GAAP 取消） ni Net Income (Loss) 净利润 ceq Common/Ordinary Equity - Total 普通股股东权益总额 che Cash and Short-Term Investments 现金与短期投资 ch Cash 现金持有 oancf Operating Activities - Net Cash Flow 经营活动现金流净额 dp Depreciation and Amortization 折旧和摊销 ppegt Property, Plant and Equipment - Total (Gross) 固定资产总额 ppent Property, Plant and Equipment - Total (Net) 固定资产净额 intan Intangible Assets - Total 无形资产总额 dvc Dividends Common/Ordinary 现金股利 re Retained Earnings 留存收益 csho Common Shares Outstanding 流通中普通股股数 prcc_f Price Close - Annual - Fiscal 会计年度结束时的股票收盘价 6 常用指标 这里我列出一些常见的财务指标 1234567891011121314151617181920212223242526xtset gvkey fyeargen Size = ln(at) // 企业规模gen MarketCap = ln(prcc_f * csho) // 公司市值规模bys gvkey: egen AGE = min(fyear)replace Age = fyear - AGE // 企业年龄，因为 IPO 日期不全，一般研究采用数据最早在 Compustat 中出现的年份作为企业出生日gen Lev = lt / at // 总负债除以总资产gen Lev_long = dltt / at // 长期负债除以总资产gen Book_lev = (dltt + dlc) / at // 长期负债 + 短期负债 除以 总资产gen ROA = ni / at // net income 除以总资产（可以考虑滞后一期的总资产）gen ROA2 = oiadp / at // Operating Income After Depreciation 除以总资产gen ROE = ni / ceq // Net income 除以账面价值gen ROE2 = oiadp / ceq // Operating Income After Depreciation 除以账面价值gen Sales_growth = sale / L.sale - 1 // sales 增长率gen Assets_growth = at / L.at - 1 // 总资产增长率gen MtoB = prcc_f * csho / ceq // 市值账面比gen Cash = che / at // 现金及其等价物持有gen Cash2 = ch / at // 现金持有gen Cachflow = (ibc + dp) / at // 经营活动现金流gen Cashflow_net = oancf / at // 经营活动现金流净额gen Intan_rate = intan / at // 无形资产比例gen Div = dvc / at // 现金股利gen DDIV = (Div &gt; 0) // 是否支付现金股利，建议先把 DIV 缺失值替换为 0gen Zscore = 3.3 * (ebit / at) + 0.99 * (sale / at) + 0.6 * (csho * prcc_f / lt) + 1.2 * (act / at) + 1.4 * (re / at) // Altman Zgen PPE = ppegt / at // 固定资产 grossgen PPE_net = ppent / at // 固定资产净额","link":"/2025/11/17/20-CCM/"},{"title":"The little SAS book 学习笔记 - 第二章 导入数据到 SAS","text":"The little SAS book 学习笔记 2.1 导入数据到 SAS 的办法 直接输入 利用文件创建 其他软件数据文件转化，比如 Stata 的 dta 直接读取其他软件数据文件 2.2 使用 VIEWTABLE 窗口输入数据不建议 2.3 使用导入向导读取文件第一步 如果要导入 csv 就选择下面那行 第二步 第三步 第四步 第五步 2.4 指定原始数据位置内部原始数据 使用 CARD 语句创建数据集 1234567891011DATA uspresidents; INPUT Presidents $ Party $ Number; CARDS; Adams F 2 Lincoln R 16 Grant R 18 Kennedy D 35 ;RUN;PROC PRINT DATA = uspresidents;RUN; 外部数据文件 使用 INFILE 语句 12345DATA Presidents; INFILE './training/data/Presidents.txt' LRECL=2000; INPUT President $ Party $ Number; PUT President= Party= Number=;RUN; 2.5 读取空格分隔的原始数据我们现在导入一个叫做 ToadJump 的数据 1234567Lucky 2.3 1.9 . 3.0Spot 4.6 2.5 3.1 .5Tubs 7.1 . . 3.8Hop 4.5 3.2 1.9 2.6Noisy 3.8 1.3 1.8 1.5Winner 5.7 . . . 可以看到，第五行的数据串行了，那么 SAS 能否准确读取呢？ 12345678DATA toads; INFILE './training/data/ToadJump.dat'; INPUT ToadName $ Weight Jump1 Jump2 Jump3; /* Specify variables' names */ /* Notice the log: NOTE: SAS went to a new line when INPUT statement reached past the end of a line. */RUN;PROC PRINT DATA = toads; TITLE 'SAS Data Set Toads'; /* Specify title of result table */RUN; 可以看到，只要当前行数低于变量数，那么 SAS 就会继续将下一行数据读取为变量值，SAS 的日志中也记录了这一个事件 这里注意一个细节，代码中用了 $ 声明 ToadName 的变量类型为字符型，而数值型则不需要特别声明 2.6 读取按列排列的原始数据其实就是按照列长度和范围读取变量 代码操作： 12345678DATA teams; INFILE './training/data/OnionRing.dat'; INPUT VisitingTeam $ 1-20 ConcessionSales 21-24 BleacherSales 25-28 OurHits 29-31 TheirHits 32-34 OurRuns 35-37 TheirRuns 38-40;RUN;PROC PRINT DATA = teams; TITLE 'SAS Data Set Sales'; /* Specify title of result table */RUN; 2.7 读取非标准格式数据SAS 会将读取的日期转化为距离 1960 年 1 月 1 日的天数 一共有三种输入格式基本类型： 字符 数值 日期 $informatw. informatw.d informatw. $ 的作用是声明字符型，前面已经提过 w 表示 width，字符或者数值的宽度 d 代表小数位数 代码示例 数据文件： 123456Alicia Grossman 13 c 10-28-2012 7.8 6.5 7.2 8.0 7.9Matthew Lee 9 D 10-30-2012 6.5 5.9 6.8 6.0 8.1Elizabeth Garcia 10 C 10-29-2012 8.9 7.9 8.5 9.0 8.8Lori Newcombe 6 D 10-30-2012 6.7 5.6 4.9 5.2 6.1Jose Martinez 7 d 10-31-2012 8.9 9.510.0 9.7 9.0Brian Williams 11 C 10-29-2012 7.8 8.4 8.5 7.9 8.0 代码文件： 12345678DATA content; INFILE './training/data/Pumpkin.dat'; INPUT Name $16. Age 3. +1 Type $UPCASE1. +1 Date MMDDYY10. (Score1 Score2 Score3 Score4 Score5) (4.1); /* Max for char is 32767, default is 8 */RUN;PROC PRINT DATA = content; TITLE 'Pimpkin Carving Content'; /* Specify title of result table */RUN; 其中，代码的 +1 表示跳过一列 4.1 表示所有的数值 Score 都是保留一位小数，所以在 9.510.0 处可以精准识别 2.8 常见输入格式 2.9 混合的输入样式示例数据 12345Yellowstone ID/MT/WY 1872 4,065,493Everglades FL 1934 1,398,800Yosemite CA 1864 760,917Great Smoky Mountains NC/TN 1926 520,269Wolf Trap Farm VA 1966 130 示例代码 1234567DATA nationalparks; INFILE './training/data/NatPark.dat'; INPUT ParkName $ 1-22 State $ Year @40 Acreage COMMA9.; /* @40 means the cursor move to 40 col */RUN;PROC PRINT DATA = nationalparks; TITLE 'Selected National Parks'; /* Specify title of result table */RUN; 解释 ParkName 的输入格式为字符，列范围为 1-22，这是因为它中间有空格 State 指定为字符，没有空格，直接输入即可 Year 和 Acreage 没有指定，默认为数值型 中间的 @40 表示读取位置跳到第 40 列 COMMA9. 告知 SAS 读取 9 列，即使是空白也会读取，COMMA表示告知数据里用了逗号做千位分隔符 2.10 读取杂乱的原始数据","link":"/2025/11/16/19-SAS-learning/"},{"title":"The little SAS book 学习笔记 -  第一章 SAS 软件使用入门","text":"The little SAS book 学习笔记 1.1 SAS 语言基本知识 SAS 程序是按顺序执行的 SAS 遵循一些语法规则 每一条 SAS 语句都以分号结尾 SAS 语句不区分大小写 一条语句可以写在多行 多条语句可以写在一行 语句可以从任意列开始 注释 SAS 的注释有两种方式： 123* 第一种方式;/* 第二种方式 */ 1.2 SAS 数据集和大多数软件一样，SAS 也将每一列叫做变量，每一行叫做观测 数据类型 数值型 字符型 缺失值 句点表示 数据集大小 变量与观测的最大数量取决于电脑性能 变量名注意事项 其实和 Python 这些变量名要求差不多，不要用数字开头就好 1.3 DATA 步和 PROC 步DATA 步：读取和修改数据，创建 SAS 数据集 PROC 步：完成特定分析或功能，产生结果或报表 代码示例： 123456DATA distance; Miles = 26.22; Kilometers = 1.61 * Miles;RUN;PROC PRINT DATA = distance;RUN; 结果展示： 1.4 DATA 步的内置循环这部分解释了 DATA 步是如何逐行执行语句和逐条处理观测的，下图即可概括： 关于如何逐条输出数据，可以看后续讲解中的 OUTPUT 语句 1.5 选择提交 SAS 程序的模式窗口提交 SAS Enterprise Guide 远程提交 这个不用管 批处理或者后台模式 使用 CMD 或者 BATCH 进行批处理（应该 1.6 SAS 窗口环境下的窗口和命令 1.7 在 SAS 窗口环境中提交程序见 1.5，提交后会在日志窗口看到运行步骤 1.8 阅读 SAS 日志日志包含的内容大致如下： 1.9 查看结果 1.10 SAS 数据逻辑库数据的临时存放区 Work 是默认的逻辑库，其他的都是 SAS 自带的示例数据 他其实对应电脑上的一个文件夹，如下： 可以看到里面包含了刚刚运行的产生的数据文件（sas7bdat）、生成的结果（htm）、数据信息（sas7bitm） 1.11 在 VIEWTABLE 窗口中查看数据集双击逻辑库中的数据文件即可在 VIEWTABLE 中查看数据 第一次使用的时候可能变量名会显示为标签 label 而不是变量名，只要在视图中调整即可 1.12 用 SAS 资源管理器查看数据集属性右键数据文件就可以查看了（不重要） 1.13 使用 SAS 系统选项一般不需要修改，除非有很强的自定义动机","link":"/2025/11/16/18-SAS-learning/"},{"title":"The little SAS book 学习笔记 - SAS 安装指引","text":"The little SAS book 学习笔记 1 SAS 安装教程 自行搜索，本学习资料采用 9.4 Windows 版本的 SAS 安装后没有增强型编辑器，参考（我也忘了是哪篇解决的了，应该是缺少了 VC 组件，最后通过 regsvr32注册）： https://blog.csdn.net/qq_37911115/article/details/110766336 https://blog.csdn.net/qq_44127863/article/details/106164237?spm=1001.2014.3001.5506 https://zhuanlan.zhihu.com/p/435985302 2 SAS 相关配置 建议使用英文版，中文版可能因为编码问题，无法下载 WRDS 内容 设置前先勾选 Save settings on exit，否则无法保存设置 字体建议选择 Consolas 或者 Consolas-with-Yahei，自定义一个工作目录 进入 ~/SASHOME/SASFoundation/9.4/nls/en 文件夹 输入下面两行代码即可，字号自己看着来 123/* 写入 sasv9.cfg 最后一行 */-SASINITIALFOLDER &quot;path/to/your/work/directory&quot;-SYSGUIFONT &quot;Consolas-with-Yahei&quot; 12 由于序列号过期，可能需要搭配 RunAsDate 才能正常使用，回答正确时间，自行搜索操作 3 成功运行界面","link":"/2025/11/16/17-SAS-learning/"},{"title":"AI prompt course -- second day","text":"AI prompt course notes 1 Pre-settings API setting 12345from openai import OpenAIimport osfrom dotenv import load_dotenv, find_dotenv_ = load_dotenv(find_dotenv()) # read local .env file Function setting 123456789client = OpenAI()def get_completion(prompt, model=&quot;Qwen/Qwen2.5-7B-Instruct&quot;, temperature=0.6): messages = [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}] response = client.chat.completions.create( model=model, messages=messages, temperature=temperature, # this is the degree of randomness of the model's output ) return response.choices[0].message.content 2 Iterative Prompt Develelopment Example – a fact sheet of mid-century inspired office furniture 12345678910111213141516171819202122232425262728293031323334353637383940fact_sheet_chair = &quot;&quot;&quot;OVERVIEW- Part of a beautiful family of mid-century inspired office furniture,including filing cabinets, desks, bookcases, meeting tables, and more.- Several options of shell color and base finishes.- Available with plastic back and front upholstery (SWC-100)or full upholstery (SWC-110) in 10 fabric and 6 leather options.- Base finish options are: stainless steel, matte black,gloss white, or chrome.- Chair is available with or without armrests.- Suitable for home or business settings.- Qualified for contract use.CONSTRUCTION- 5-wheel plastic coated aluminum base.- Pneumatic chair adjust for easy raise/lower action.DIMENSIONS- WIDTH 53 CM | 20.87”- DEPTH 51 CM | 20.08”- HEIGHT 80 CM | 31.50”- SEAT HEIGHT 44 CM | 17.32”- SEAT DEPTH 41 CM | 16.14”OPTIONS- Soft or hard-floor caster options.- Two choices of seat foam densities: medium (1.8 lb/ft3) or high (2.8 lb/ft3)- Armless or 8 position PU armrestsMATERIALSSHELL BASE GLIDER- Cast Aluminum with modified nylon PA6/PA66 coating.- Shell thickness: 10 mm.SEAT- HD36 foamCOUNTRY OF ORIGIN- Italy&quot;&quot;&quot; 3 Ouputs1) Raw prompt12345678910111213prompt = f&quot;&quot;&quot;Your task is to help a marketing team create adescription for a retail website of a product basedon a technical fact sheet.Write a product description based on the informationprovided in the technical specifications delimited bytriple backticks.Technical specifications: ```{fact_sheet_chair}```&quot;&quot;&quot;response = get_completion(prompt)print(response) Output Introducing the Mid-Century Inspired Office Chair, a stunning addition to any modern workspace or home office. Crafted as part of a beautifully designed family of office furniture, this chair seamlessly blends style and functionality, offering a versatile solution for both personal and professional environments. &nbsp; **Design & Comfort** Available in a variety of shell colors and base finishes, this chair offers a wide range of customization options to suit any aesthetic. Choose from a sleek stainless steel, matte black, gloss white, or chrome base to match your existing decor. The chair is available in two upholstery options: SWC-100 with plastic back and front upholstery in 10 fabric and 6 leather choices, or the more luxurious SWC-110 with full upholstery. Whether you prefer the softness of fabric or the sophistication of leather, this chair will provide unparalleled comfort. &nbsp; **Comfortable Seating Experience** The chair features a 5-wheel plastic coated aluminum base for smooth, quiet movement, and a pneumatic adjustment mechanism that allows for easy raise and lower actions. The seat dimensions are meticulously designed to ensure optimal comfort, with a width of 53 cm (20.87\"), depth of 51 cm (20.08\"), and a seat height of 44 cm (17.32\"). The seat depth is 41 cm (16.14\"), providing ample support for long periods of sitting. &nbsp; **Customization Options** Enhance your comfort further with adjustable seat foam densities—choose from medium (1.8 lb/ft³) or high (2.8 lb/ft³) to find the perfect level of support. For even more personalization, opt for soft or hard-floor caster options to suit your specific needs. Additionally, the chair is available with or without armrests, and for those who need extra support, the 8-position PU armrests offer a range of adjustments to find the perfect fit. &nbsp; **Durability and Quality** Constructed with a sturdy cast aluminum base and a modified nylon PA6/PA66 coating, the shell is both durable and stylish. The seat is upholstered with HD36 foam, ensuring long-lasting comfort and support. This chair is manufactured in Italy, known for its high-quality craftsmanship and attention to detail. &nbsp; **Versatile Use** Suitable for both home and business settings, this chair is also qualified for contract use, making it a perfect choice for offices, meeting rooms, or even high-end residential spaces. Its sleek design and versatile features make it an ideal companion for any workspace or home office. &nbsp; Elevate your work environment with the Mid-Century Inspired Office Chair. Experience comfort, style, and functionality in perfect harmony. 2) Issue 1: The text is too long We require it output within 50 words 123456789101112131415prompt = f&quot;&quot;&quot;Your task is to help a marketing team create adescription for a retail website of a product basedon a technical fact sheet.Write a product description based on the informationprovided in the technical specifications delimited bytriple backticks.Use at most 50 words.Technical specifications: ```{fact_sheet_chair}```&quot;&quot;&quot;response = get_completion(prompt)print(response) Output Elevate your office with the mid-century inspired SWC-100 chair. Available in multiple shell colors and base finishes, it features soft or hard-floor casters and adjustable armrests. Perfect for both home and business settings. 2) Issue 2: Text focus on the wrong details Ask it to focus on the aspects that are relevant to the intended audiences 12345678910111213141516171819202122prompt = f&quot;&quot;&quot;Your task is to help a marketing team create adescription for a retail website of a product basedon a technical fact sheet.Write a product description based on the informationprovided in the technical specifications delimited bytriple backticks.The description is intended for furniture retailers,so should be technical in nature and focus on thematerials the product is constructed from.At the end of the description, include every 7-characterProduct ID in the technical specification.Use at most 50 words.Technical specifications: ```{fact_sheet_chair}```&quot;&quot;&quot;response = get_completion(prompt)print(response) Output Crafted from cast aluminum with a nylon PA6/PA66 coating, this mid-century inspired chair features an HD36 foam seat and adjustable base. Available in plastic or full upholstery with 16 color options. Suitable for both home and business. SWC-100 | SWC-110. Issue 3: Require a table for description1234567891011121314151617181920212223242526272829303132from IPython.display import display, HTMLprompt = f&quot;&quot;&quot;Your task is to help a marketing team create adescription for a retail website of a product basedon a technical fact sheet.Write a product description based on the informationprovided in the technical specifications delimited bytriple backticks.The description is intended for furniture retailers,so should be technical in nature and focus on thematerials the product is constructed from.At the end of the description, include every 7-characterProduct ID in the technical specification.After the description, include a table that gives theproduct's dimensions. The table should have two columns.In the first column include the name of the dimension.In the second column include the measurements in inches only.Give the table the title 'Product Dimensions'.Format everything as HTML that can be used in a website.Place the description in a &lt;div&gt; element.Technical specifications: ```{fact_sheet_chair}```&quot;&quot;&quot;response = get_completion(prompt)display(HTML(response.replace('```html\\n', '').replace('```', ''))) Reference https://github.com/GitHubDaily/ChatGPT-Prompt-Engineering-for-Developers-in-Chinese https://learn.deeplearning.ai/courses/chatgpt-prompt-eng/lesson/zi9lz/guidelines","link":"/2025/05/25/16-AI-prompt-beginner/"},{"title":"AI prompt course -- first day","text":"AI prompt course notes 1 Two types of LLMs Base LLMs Instruct tuned LLMs (i.e., ChatGPT, DeepSeek, et al.) 2 Environment variablesUse .env file to provide parameters for Jupyter or Python. An example for a .env file can be 12OPENAI_API_KEY='sk-***'OPENAI_BASE_URL='https://api.siliconflow.cn/v1' # Here we use SiliconFlow's free models Save this file in your Python or Jupyter source code directory. Then, you can load these parameters by the following code: 123456import osfrom openai import OpenAI # version 1.78.0# load .env to environment variablesfrom dotenv import load_dotenv, find_dotenv_ = load_dotenv(find_dotenv()) We use the Python library provided by OpenAI, openai, to chat with models. 123456789client = OpenAI()def get_completion(prompt, model=&quot;Qwen/Qwen2.5-7B-Instruct&quot;, temperature=0.6): messages = [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}] response = client.chat.completions.create( model=model, messages=messages, temperature=temperature, # this is the degree of randomness of the model's output ) return response.choices[0].message.content Here, we generate a new object named client, and define a function named get_completion. The main part of this function is the request from client, which needs two key parameters: model and messages. The parameter temperature is optional and its function is adjust the creativity of LLM. The higher the value, the more creative the response. Generally, when we employ LLMs as translators, the value is typically set below 0.4. We set the default model as Qwen2.5-7B-Instruct, the newest open-source model provided by a Chinese company, Alibaba. The variable messages is a single-element list with a dictionary. In the dictionary, the key “role” can be “user” or “system”, while the key “content” is the prompt or instruct, respectively. Now, we don’t set any instruct for this model, and directly get the response from the one-time request. 3 Two principles in promptingPrinciple 1: Write clear and specific instructions1) Use delimiters to clearly indicate distinct parts of the input Delimiters can be anything like: ```, “””, &lt;tag&gt;&lt;/tag&gt;, : 12345678910111213141516171819text = f&quot;&quot;&quot;You should express what you want a model to do by \\providing instructions that are as clear and \\specific as you can possibly make them. \\This will guide the model towards the desired output, \\and reduce the chances of receiving irrelevant \\or incorrect responses. Don't confuse writing a \\clear prompt with writing a short prompt. \\In many cases, longer prompts provide more clarity \\and context for the model, which can lead to \\more detailed and relevant outputs.&quot;&quot;&quot;prompt = f&quot;&quot;&quot;Summarize the text delimited by triple backticks \\into a single sentence.&lt;input&gt;{text}&lt;/input&gt;&quot;&quot;&quot;content = get_completion(prompt=prompt, temperature=0.6)print(content) Output To guide a model effectively, provide clear and specific instructions, often in a longer format, to reduce irrelevant or incorrect responses and ensure more detailed and relevant outputs. 2) Ask for a structural output like JSON and HTML Requiring the model provide a specific format can help your next step. 12345678prompt = f&quot;&quot;&quot;Generate a list of three made-up book titles along \\with their authors and genres.Provide them in JSON format with the following keys:book_id, title, author, genre.&quot;&quot;&quot;response = get_completion(prompt)print(response) Output &grave;&grave;&grave;json [ { \"book_id\": \"001\", \"title\": \"Whispers of the Wraith\", \"author\": \"Eleanor Blackwood\", \"genre\": \"Fantasy\" }, { \"book_id\": \"002\", \"title\": \"The Last Starlight Sonata\", \"author\": \"Liam Fletcher\", \"genre\": \"Science Fiction\" }, { \"book_id\": \"003\", \"title\": \"Murder at the Mosaic Market\", \"author\": \"Sophie Hart\", \"genre\": \"Mystery\" } ] &grave;&grave;&grave; #### 3) Ask the model to check whether the conditions are satisfied Maybe some of the input is not satisfy your requirement, and you can ignore them. 123456789101112131415161718192021222324252627282930# Sample 1text_1 = f&quot;&quot;&quot;Making a cup of tea is easy! First, you need to get some \\water boiling. While that's happening, \\grab a cup and put a tea bag in it. Once the water is \\hot enough, just pour it over the tea bag. \\Let it sit for a bit so the tea can steep. After a \\few minutes, take out the tea bag. If you \\like, you can add some sugar or milk to taste. \\And that's it! You've got yourself a delicious \\cup of tea to enjoy.&quot;&quot;&quot;prompt = f&quot;&quot;&quot;You will be provided with text delimited by triple quotes.If it contains a sequence of instructions, \\re-write those instructions in the following format:Step 1 - ...Step 2 - ……Step N - …If the text does not contain a sequence of instructions, \\then simply write \\&quot;No steps provided.\\&quot;\\&quot;\\&quot;\\&quot;{text_1}\\&quot;\\&quot;\\&quot;&quot;&quot;&quot;response = get_completion(prompt)print(&quot;Completion for Text 1:&quot;)print(response) Output Completion for Text 1: Step 1 - Get some water boiling. Step 2 - Grab a cup and put a tea bag in it. Step 3 - Once the water is hot enough, pour it over the tea bag. Step 4 - Let it sit for a bit so the tea can steep. Step 5 - After a few minutes, take out the tea bag. Step 6 - If you like, add some sugar or milk to taste. 123456789101112131415161718192021222324252627282930# Sample 2text_2 = f&quot;&quot;&quot;The sun is shining brightly today, and the birds are \\singing. It's a beautiful day to go for a \\walk in the park. The flowers are blooming, and the \\trees are swaying gently in the breeze. People \\are out and about, enjoying the lovely weather. \\Some are having picnics, while others are playing \\games or simply relaxing on the grass. It's a \\perfect day to spend time outdoors and appreciate the \\beauty of nature.&quot;&quot;&quot;prompt = f&quot;&quot;&quot;You will be provided with text delimited by triple quotes.If it contains a sequence of instructions, \\re-write those instructions in the following format:Step 1 - ...Step 2 - ……Step N - …If the text does not contain a sequence of instructions, \\then simply write \\&quot;No steps provided.\\&quot;\\&quot;\\&quot;\\&quot;{text_2}\\&quot;\\&quot;\\&quot;&quot;&quot;&quot;response = get_completion(prompt)print(&quot;Completion for Text 2:&quot;)print(response) Output Completion for Text 2: No steps provided. 4) “Few-shot” prompting Giving some samples can help models learn the output styles. 1234567891011121314prompt = f&quot;&quot;&quot;Your task is to answer in a consistent style.&lt;child&gt;: Teach me about patience.&lt;grandparent&gt;: The river that carves the deepest \\valley flows from a modest spring; the \\grandest symphony originates from a single note; \\the most intricate tapestry begins with a solitary thread.&lt;child&gt;: Teach me about resilience.&quot;&quot;&quot;response = get_completion(prompt)print(response) Output &lt;grandparent&gt;: Imagine a little sapling in a garden. It faces many challenges—dry spells, strong winds, even the shadow of a taller tree. Yet, it doesn't give up. Instead, it learns to bend and stretch, growing stronger with each obstacle. Just like that sapling, resilience is about not letting difficulties defeat you. It's about finding the strength to keep going, even when things get tough. Remember, every great journey starts with a single step, and every great achievement is built upon countless small efforts. Principle 2: Give the model time to “think”1) Specify the steps required to complete a task Avoid models giving wrong answers too hastily. 123456789101112131415161718192021prompt_2 = f&quot;&quot;&quot;Your task is to perform the following actions:1 - Summarize the following text delimited by &lt;&gt; with 1 sentence.2 - Translate the summary into French.3 - List each name in the French summary.4 - Output a json object that contains the following keys: french_summary, num_names.Use the following format:Text: &lt;text to summarize&gt;Summary: &lt;summary&gt;Translation: &lt;summary translation&gt;Names: &lt;list of names in Italian summary&gt;Output JSON: &lt;json with summary and num_names&gt;Text: &lt;{text}&gt;&quot;&quot;&quot;response = get_completion(prompt_2)print(&quot;\\nCompletion for prompt 2:&quot;)print(response) Output Completion for prompt 2: Summary: Jack and Jill, siblings, embark on a quest to fetch water but have a mishap on the hill, yet their spirits remain adventurous. Translation: Jack et Jill, frères et sœurs, entreprennent une quête pour ramener de l'eau mais ont un malheur sur la colline, mais leurs esprits restent aventuriers. Names: Jack, Jill Output JSON: { \"french_summary\": \"Jack et Jill, frères et sœurs, entreprennent une quête pour ramener de l'eau mais ont un malheur sur la colline, mais leurs esprits restent aventuriers.\", \"num_names\": 2 } 2) Instruct the model to work out its own solution before running to a conclusion12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758prompt = f&quot;&quot;&quot;Your task is to determine if the student's solution \\is correct or not.To solve the problem do the following:- First, work out your own solution to the problem.- Then compare your solution to the student's solution \\and evaluate if the student's solution is correct or not.Don't decide if the student's solution is correct untilyou have done the problem yourself.Use the following format:Question:```question here```Student's solution:```student's solution here```Actual solution:```steps to work out the solution and your solution here```Is the student's solution the same as actual solution \\just calculated:```yes or no```Student grade:```correct or incorrect```Question:```I'm building a solar power installation and I need help \\working out the financials.- Land costs $100 / square foot- I can buy solar panels for $250 / square foot- I negotiated a contract for maintenance that will cost \\me a flat $100k per year, and an additional $10 / square \\footWhat is the total cost for the first year of operations \\as a function of the number of square feet.```Student's solution:```Let x be the size of the installation in square feet.Costs:1. Land cost: 100x2. Solar panel cost: 250x3. Maintenance cost: 100,000 + 100xTotal cost: 100x + 250x + 100,000 + 100x = 450x + 100,000```Actual solution:&quot;&quot;&quot;response = get_completion(prompt)print(response) Output &grave;&grave;&grave; Let x be the size of the installation in square feet. &nbsp; 1. Land cost: $100 per square foot, so the cost for x square feet is 100x. 2. Solar panel cost: $250 per square foot, so the cost for x square feet is 250x. 3. Maintenance cost: $100,000 per year plus $10 per square foot, so the cost for x square feet is 100,000 + 10x. &nbsp; The total cost for the first year of operations is the sum of these three costs: Total cost = 100x + 250x + 100,000 + 10x = 360x + 100,000 &grave;&grave;&grave; Is the student's solution the same as actual solution just calculated: &grave;&grave;&grave; no &grave;&grave;&grave; Student grade: &grave;&grave;&grave; incorrect &grave;&grave;&grave; &nbsp; The student's solution is incorrect because they incorrectly added the maintenance cost term. The maintenance cost should be $100,000 per year plus $10 per square foot, which simplifies to 10x, not 100x. Therefore, the correct total cost function is \\(360x + 100,000\\). 4 Model limitations: Hallucinations Boie is a real company, the product name is not real. 12345prompt = f&quot;&quot;&quot;Tell me about AeroGlide UltraSlim Smart Toothbrush by Boie&quot;&quot;&quot;response = get_completion(prompt)print(response) Output The AeroGlide UltraSlim Smart Toothbrush by Boie is a modern, compact, and sleek electric toothbrush designed to provide an efficient and comfortable brushing experience. Here are some key features and details about this product: &nbsp; ### Features: 1. **Slim Design**: The toothbrush is ultra-slim and lightweight, making it easy to handle and store. Its compact size is particularly beneficial for those who have limited space or find traditional toothbrushes cumbersome. &nbsp; 2. **Advanced Cleaning Technology**: Equipped with advanced cleaning technology, the AeroGlide UltraSlim aims to deliver a thorough and efficient clean. It often features multiple brush heads with different bristle strengths and shapes to cater to various dental needs. &nbsp; 3. **Smart Features**: Many models of the AeroGlide UltraSlim come with smart features such as: - **Pressure Sensors**: These sensors monitor the pressure applied during brushing and alert users if they are brushing too hard. - **Timer Function**: The toothbrush typically has a built-in timer to ensure users brush for the recommended two minutes. - **Brushing Modes**: Users can choose from different brushing modes, such as sensitive, whitening, and gum care, to target specific dental needs. - **App Integration**: Some models can connect to a mobile app, which provides feedback on brushing habits and allows for tracking progress over time. &nbsp; 4. **Ease of Use**: The brush is designed to be user-friendly, with intuitive controls and a straightforward interface. It often comes with a charging base and a travel case for easy storage and transport. &nbsp; 5. **Durability**: Boie emphasizes the durability of their products, ensuring that the brush and its components are built to last and withstand regular use. &nbsp; ### User Experience: The AeroGlide UltraSlim is designed to provide a comfortable and effective brushing experience. Its slim design and smart features make it a popular choice among those who prioritize convenience and modern technology in their oral hygiene routine. &nbsp; ### Conclusion: The Boie AeroGlide UltraSlim Smart Toothbrush is a contemporary and practical choice for individuals seeking a high-quality, efficient, and smart toothbrush. Its combination of advanced technology, user-friendly design, and smart features makes it a commendable option for maintaining good oral health in a modern lifestyle. Reference https://github.com/GitHubDaily/ChatGPT-Prompt-Engineering-for-Developers-in-Chinese https://learn.deeplearning.ai/courses/chatgpt-prompt-eng/lesson/zi9lz/guidelines","link":"/2025/05/10/15-AI-prompt-beginner/"},{"title":"统计学复习","text":"统计学复习，参考书目： 《统计学》第八版：贾俊平、何晓群、金勇进 《统计学导论》第四版：曾五一、肖红叶 1 基本概念（1）什么是统计学统计学是收集、处理、分析、解释数据并从数据中得出结论的科学 严格来说不是数学的分支，并且不是独立学科 主要流派包括：政治算术派（威廉·配第）、国势学派（阿亨瓦尔）、社会统计学派（克尼斯）、数理统计学派（凯特勒）：细分为经典学派、贝叶斯学派 （2）统计数据及其类型 计量尺度来看 分类数据（定类尺度和定序尺度）、数值型数据（定距尺度和定比尺度）（贾俊平） 数据的尺度包括：定类尺度、定序尺度、定距尺度、定比尺度（曾五一） 收集方法来看 观测数据：通过观察或观测收集到的数据 实验数据：在实验中控制实验对象得到的数据 从现象与时间关系来看 横截面数据（静态数据）：在同一时间对同一总体内不同单位的数量进行观察而获得的数据 时间序列数据（动态数据）：在不同时间对同一总体的数量表现进行观察而获得的数据 面板数据：同时在时间和横截面空间上取得的二维数据 数据的表现形式 绝对数、相对数、平均数 （3）总体、样本、参数、统计量和变量统计总体：根据一定目的确定所要研究的事物的全体，是由客观存在的、具有某种相同性质的许多个别事物构成的整体 总体单位（简称单位）：组成总体的各个个体 根据单位数量，总体可以分为有限总体和无限总体 样本：从总体中抽取的一部分元素的集合 总体参数：描述统计特征的概括性数字度量 样本统计量：样本的函数，用来描述样本特征的概括性数字度量 变量：说明现象某种特征的概念 分类变量 数值变量 连续型变量：在数轴上取值连续不断的变量 离散型变量：仅可通过计数获得的变量，通常取值为整数值 变量值：变量的具体取值 （4）一个案例 （5）数据的来源数据主要可分为一手数据与二手数据 一手数据来源包括但不限于直接观察、统计调查、实验记录、人员采访等 二手数据来源包括但不限于统计年鉴、相关期刊、有关网站、数据库等 （6）概率抽样与非概率抽样概率抽样：也称随机抽样，是指遵循随机原则进行的抽样，总体中每个单位都有一定的机会被选入样本。这个概率不一定要相等，但是是可计算的。（等概率抽样和不等概率抽样） 简单随机抽样：从包括总体 $N$ 个单位的抽样框中随机地、一个个地抽取 $n$ 个单位作为样本，每个单位的入样概率是相等的。（1948年的总统选举获胜的方法） 分层抽样 整群抽样 系统抽样 多阶段抽样 非概率抽样：抽取样本时不是依据随机原则，而是根据研究目的对数据的要求，采用某种方式从总体中抽出部分单位对其实施调查。 方便抽样 判断抽样 自愿样本（文学文摘的方式，曾经在1916年到1932年间成功预测当选的总统） 滚雪球抽样 配额抽样（盖洛普公司的方式，1936年的总统选举获胜的方法） （7）抽样误差与非抽样误差抽样误差：由抽样随机性引起的样本结果与总体真值之间的差异，是可计算的 非抽样误差：除了抽样误差外，由其他原因引起的样本观测结果与总体真值之间的差异 抽样框误差：抽样框不全或者抽样框未更新 回答误差 理解误差 记忆误差 有意识误差 无回答误差 调查员误差 测量误差 （8）数据的预处理 数据审核 数据筛选 数据排序 （9）分类数据的整理与图示统计分组：根据统计研究的目的和客观现象的内在特点，按某个标志（或几个标志）把被研究的总体划分为若干个不同性质的组。统计分组的对象是总体。统计标志可以是品质标志，也可以是数量标志。 统计分组的种类 按分组标志的多少：简单分组和复合分组 按分组的标志性质不同：数量分组（定距尺度和定比尺度）和品质分组（定类尺度和定序尺度） 统计分组的原则：穷尽原则和互斥原则 品质分组的方法：需要制定一套标准的分类指引 数量分组的方法： 单项式分组和组距式分组 单项式分组（1、2、3、4） 组距式分组（1、2、3、4个及以上 或 100以下、100-200、200以上） 组限：一组数据中上下限的距离，相邻两组的界限。 间断型组距分组（1、2、3、4个及以上）：组限不相连的数量分组方法 连续型组距分组（100以下、100-200、200以上）：组限相连的数量分组方法，一般要求左闭右开 等距分组和异距分组 斯特杰斯经验公式：$n = 1 + 3.3\\lg N$，$d = R / n = (x_{max} - x_{min}) / (1 + 3.3 \\lg N)$ 统计数据的显示：统计表和统计图 （10）集中趋势的度量 平均数 简单平均数 加权平均数 调和平均数 几何平均数 中位数 分位数 众数 （11）离散程度的度量 全距 四分位距 方差和标准差 离散系数 标准分数（z-score） （12）分布的形状 偏度系数 $SK=\\frac{n}{(n-1)(n-2)}\\sum\\left(\\frac{x_i-\\overline{x}}{s}\\right)^3$ 峰度系数 $K=\\frac{n(n+1)}{(n-1)(n-2)(n-3)}\\sum\\left(\\frac{x_i-\\overline{x}}{s}\\right)^4-\\frac{3(n-1)^2}{(n-2)(n-3)}$ 2 统计量及抽样分布（1）统计量的定义 （2）常用统计量 （3）抽样分布 样本均值分布：近似服从正态分布，$\\overline{x} \\overset{.}{\\sim} N(\\mu, \\sigma ^2 / n)$ 样本方差分布 样本比率分布 卡方分布：若 $X_1, X_2, \\cdots , X_n$ 是独立同分布于正态总体 $N(\\mu, \\sigma^2)$ 的随机变量，且 $\\chi^{2} = X_{1}^2 + X_{2}^2 + \\cdots + X_{n}^2$，那么 $\\chi^2 \\sim \\chi^2(n)$ $E(\\chi^2) = n$ $D(\\chi^2) = 2n$ $x_1, x_2, \\cdots x_n$ 是来自正态总体 $N(\\mu, \\sigma^2)$ 的一个样本，$\\overline{x}, s^2$ 分别是他们的均值和方差，则 $\\overline{x}$ 和 $s^2$ 独立 $\\overline{x} \\sim N(\\mu, \\sigma^2/n)$，标准化后，$\\frac{\\overline{x} - \\mu}{\\sigma/\\sqrt{n}} \\sim N(0, 1)$ $\\frac{(n-1)s^2}{\\sigma^2} \\sim \\chi^2(n-1)$ $t$ 分布：若$X_1 \\sim N(0, 1), X_2 \\sim \\chi^2(n)$，那么 $t = \\frac{X_1}{\\sqrt{X_2/n}} \\sim t(n)$ 若$t \\sim t(n)$，则$t^2 \\sim F(1, n)$ $x_1, x_2, \\cdots x_n$是来自正态总体$N(\\mu, \\sigma^2)$的一个样本，$\\overline{x}, s^2$分别是他们的均值和方差，则有$t = \\frac{\\sqrt{n} (\\overline{x} - \\mu)}{s} = \\frac{\\overline{x} - \\mu}{s/\\sqrt{n}} \\sim t(n-1)$ （注意变形） $x_1, x_2, \\cdots x_m$来自正态总体$N(\\mu_1, \\sigma_1^2)$，$y_1, y_2, \\cdots y_n$来自正态总体$N(\\mu_2, \\sigma_2^2)$，如果总体中$\\sigma_1 = \\sigma_2 = \\sigma$，那么样本中满足，$\\frac{(\\overline{x}-\\overline{y})-(\\mu_1 - \\mu_2)}{s_w^2\\sqrt{\\frac{1}{m}+\\frac{1}{n}}} \\sim t(m + n -2)$，其中，$s_w$是两个样本的方差的加权平均，即 $s_w=\\frac{(m-1)s_x + (n-1)s_n}{m+n-2} = \\frac{\\sum\\limits_{i=1}^{m}(x_i-\\overline{{x}})^2 + \\sum\\limits_{i=1}^{n}(y_i-\\overline{{y}})^2}{m+n-2}$ $F$ 分布：若 $X_1 \\sim \\chi^2(m), X_2 \\sim \\chi^2(n)$ ，$F = \\frac{X_1/m}{X_2/n}$，那么 $F \\sim F(m, n)$ 服从$F$分布的随机变量的倒数依然服从$F$分布，$F \\sim F(m, n), 1/F \\sim F(n, m)$ $F_{\\alpha}(m, n) = \\frac{1}{F_{1-\\alpha}(n, m)}$ $x_1, x_2, \\cdots x_m$来自正态总体$N(\\mu_1, \\sigma_1^2)$，$y_1, y_2, \\cdots y_n$来自正态总体$N(\\mu_2, \\sigma_2^2)$，那么有，$F = \\frac{s_x^2/\\sigma_1^2}{s_y^2/\\sigma_2^2} \\sim F(m-1, n-1)$（可以注意到，这个表达式与$\\mu$无关） 3 参数估计（1）基本概念参数估计：用样本统计量去估计总体参数（基本原理） 估计量：用来估计参数的统计量（随机变量） 估计值：根据一个具体的样本估计出来的值（常数） 名词 概念 点估计 用样本一个统计量去估计总体未知参数（包括矩估计和极大似然估计） 区间估计 最后求出一个区间，这个区间包含真实值的概率称为置信水平 矩估计 点估计的一种，用样本的中心距或者原点矩替换总体的中心距或者原点矩 极大似然估计 点估计的一种，假装抽到了最有可能的结果，调整参数 $\\theta$ 让这组样本被抽到的可能性（似然函数$L(\\theta)$）最大 预测区间估计 对预测值的区间估计 无偏性/无偏估计 最终估计量的期望 $E(\\hat{\\theta})$ 等于实际值 $\\theta$ ，估计值围绕着实际值上下波动，没有系统误差 有效性 在无偏性的基础上，减小波动的幅度（方差），越小越有效 一致性/相合性/相合估计 当样本量足够大的时候，估计值朝着真实值接近，则称为相合估计 均方误差$MSE$ $E(\\hat{\\theta}-\\theta)^2=Var(\\hat{\\theta})+(E\\hat{\\theta}-\\theta)^2$ 前面方差衡量有效性，后面距离中心平方衡量无偏性 点估计：$x_1, x_2, \\cdots , x_n$ 是来自总体的一个样本，总体中含有未知参数 $\\theta$，那么利用样本的一个统计量 $\\hat{\\theta}=\\hat{\\theta}(x_1, x_2, \\cdots , x_n)$ 来估计总体未知参数 $\\theta$ 的方法叫做点估计。 矩估计：总体的密度函数为 $p(x; \\theta_1, \\theta_2, \\cdots, \\theta_n)$（如果总体中含有未知参数，通常我们把它表现在总体的密度函数里），总体的 1 到 $k$ 阶原点矩（中心距也行）为 $u_1, u_2, \\cdots, u_n$。从中抽出一个样本 $x_1, x_2, \\cdots , x_n$，记这个样本的 1 到 $k$ 阶原点矩（中心距也行的）为 $a_1, a_2, \\cdots, a_n$。如果 $\\theta$ 可以表示为总体矩的函数，即 $\\theta=\\theta(u_1, u_2, \\cdots, u_n)$，那么我们用样本矩来替换总体矩，即 $\\hat{\\theta}=\\theta(a_1, a_2, \\cdots, a_n)$，得到的结果 $\\hat{\\theta}$ 称为参数 $\\theta$ 的矩估计 极大似然估计：设总体概率密度函数为 $p(x;\\theta)$，$\\theta \\in \\Theta$，$x_1, x_2, \\cdots , x_n$ 是来自总体的一个样本，将样本的联合概率函数看成 $\\theta$ 的函数，用 $L(x_1, x_2, \\cdots , x_n; \\theta)$ 表示，记为 $L(\\theta)$，若统计量满足：$L(\\hat{\\theta}) = \\underset{\\theta \\in \\Theta}{\\max} L(\\theta)$，则称 $\\hat{\\theta}$ 称为参数 $\\theta$ 的极大似然估计 区间估计：设 $\\theta$ 是总体的一个参数，其参数空间为 $\\Theta$, $x_1, \\cdots, x_n$ 是来自该总体的样本。对给定的一个 $\\alpha$ (0 &lt; $\\alpha$ &lt; 1)，假设有两个统计量 $\\hat{\\theta}_L = \\hat{\\theta}_L(x_1, \\cdots, x_n)$ 和 $\\hat{\\theta}_U = \\hat{\\theta}_U(x_1, \\cdots, x_n)$，若对任意的 $\\theta \\in \\Theta$，有 $ P_\\theta(\\hat{\\theta}_L \\leqslant \\theta \\leqslant \\hat{\\theta}_U) \\geqslant 1 - \\alpha $，则称随机区间 $[\\hat{\\theta}_L, \\hat{\\theta}_U]$ 为 $\\theta$ 的置信水平为 $1-\\alpha$ 的置信区间，或简称 $[\\hat{\\theta}_L, \\hat{\\theta}_U]$ 是 $\\theta$ 的 $1-\\alpha$ 置信区间。$\\hat{\\theta}_L$ 和 $\\hat{\\theta}_U$ 分别称为 $\\theta$ 的（双侧）置信下限和置信上限。 置信水平 $1 - \\alpha$ 有一个频率解释：在大量重复使用 $\\theta$ 的置信区间 $[\\hat{\\theta}_L, \\hat{\\theta}_U]$ 时，每次得到的样本观测值是不同的，从而每次得到的区间也是不一样的。对一次具体的观测值而言，$\\theta$ 可能在 $[\\hat{\\theta}_L, \\hat{\\theta}_U]$ 内，也可能不在。平均而言，在这大量的区间估计观测值中，至少有 $100(1 - \\alpha)%$ 包含 $\\theta$。 （2）评价指标 无偏性：$E(\\hat{\\theta}) = \\theta$ 有效性：若 $\\hat{\\theta}_1,\\hat{\\theta}_2$ 是 $\\theta$ 的两个无偏估计，那么若 $Var(\\hat{\\theta}_1) &lt; Var(\\hat{\\theta}_2)$，我们称 $\\hat{\\theta}_1$ 比 $\\hat{\\theta}_2$ 有效 一致性（相合性）：设 $\\theta \\in \\Theta$，$\\hat{\\theta} = \\hat{\\theta}_n(x_1, x_2, \\cdots, x_n)$ 是 $\\theta$ 的一个估计量，$n$ 是样本容量，如果 $\\forall \\varepsilon&gt;0$，当 $n\\rightarrow\\infty$ 时，总有 $\\underset{n\\rightarrow\\infty}{\\lim}P(|\\hat{\\theta}-\\theta|\\geq \\epsilon)=0$，那么称 $\\hat{\\theta}$ 是 $\\theta$ 的相合估计 （3）常见的参数估计 id 待估参数 条件 枢轴量 1 单个正态总体 $\\mu$ $\\sigma$ 已知 $G=\\frac{\\overline{x}-\\mu}{\\sigma/\\sqrt{n}} \\sim N(0, 1)$ 2 单个正态总体 $\\mu$ $\\sigma$ 未知 $G=\\frac{\\overline{x}-\\mu}{s/\\sqrt{n}} \\sim t(n - 1)$，OLS 3 单个正态总体 $\\sigma^2$ $\\mu$ 未知 $G=\\frac{(n-1)s^2}{\\sigma^2} \\sim \\chi^2(n-1)$ 4 二点分布 $p$ 大样本，$X \\sim b(1, p)$ $G=\\frac{\\overline{x}-p}{\\sqrt{p(1-p)/n}} \\overset{.}{\\sim} N(0, 1)$ 5 两个独立正态总体$\\mu_1 - \\mu_2$ $\\sigma_1, \\sigma_2$ 已知 $G = \\frac{\\overline{x} - \\overline{y} - (\\mu_1 - \\mu_2)}{\\sqrt{\\frac{\\sigma_1^2}{m} + \\frac{\\sigma_2^2}{n}}} \\sim N(0, 1)$ 6 两个独立正态总体$\\mu_1 - \\mu_2$ $\\sigma_1=\\sigma_2=\\sigma = ?$ $G = \\sqrt {\\frac{{mn(m + n - 2)}}{{m + n}}} \\frac{{\\bar x - \\bar y - ({\\mu _1} - {\\mu _2})}}{{\\sqrt {(m - 1)s_x^2 + (n - 1)s_y^2} }} \\sim t(m+n-2)$ 7 两个独立正态总体$\\mu_1 - \\mu_2$ $\\sigma_1/\\sigma_2=c$ $G = \\sqrt {\\frac{{mn(m + n - 2)}}{{mc + n}}} \\frac{{\\bar x - \\bar y - ({\\mu _1} - {\\mu _2})}}{{\\sqrt {(m - 1)s_x^2 + (n - 1)s_y^2/c} }} \\sim t(m+n-2)$ 8 两个独立正态总体$\\mu_1 - \\mu_2$ $\\sigma_1, \\sigma_2$ 没啥信息，但是 $m, n$ 很大 $G = \\frac{\\overline{x} - \\overline{y} - (\\mu_1 - \\mu_2)}{\\sqrt{\\frac{s_1^2}{m} + \\frac{s_2^2}{n}}} \\overset{.}{\\sim} N(0, 1)$ 9 两个独立正态总体$\\mu_1 - \\mu_2$ $\\sigma_1, \\sigma_2$ 没啥信息， $m, n$ 也很小 $G = \\frac{\\overline{x} - \\overline{y} - (\\mu_1 - \\mu_2)}{s_0} \\overset{.}{\\sim} t(l), s_0=\\sqrt{\\frac{s_x^2}{m}+\\frac{s_y^2}{n}}, l=s_0^4 / \\left(\\frac{s_x^4}{m^2(m-1)}+\\frac{s_y^4}{n^2(n-1)} \\right)$ 10 两个独立正态总体$\\sigma_1^2/\\sigma_2^2$ 无 $G = \\frac{s_x^2/\\sigma_1^2}{s_y^2/\\sigma_2^2} \\sim F(m-1, n-1)$ 估计思路（id 排序）： 通过已有样本的分布 $\\overline{x} \\sim N(\\mu, \\sigma^2)$ 进行标准化得到 $\\sigma$ 未知，应该用 $s$ 去替代 $\\sigma$ ，得到的分布是 $t$ 分布，$\\frac{\\overline{x}-\\mu}{s/\\sqrt{n}} \\sim t(n - 1)$ 涉及到方差的，单正态总体卡方分布，两正态总体 $F$ 分布，此处卡方分布。利用性质，$\\frac{(n-1)s^2}{\\sigma^2}\\sim \\chi^2(n-1)$ 此处是由中心极限定理得到的，二点分布样本均值服从如下分布，$\\overline{x} \\sim N(p, \\frac{p(1-p)}{n})$，标准化即可 因为独立，所以有，$\\overline{x} - \\overline{y} \\sim N(\\mu_1 - \\mu_2, \\sigma_1^2/m+\\sigma_2^2/n)$，标准化即可 因为独立，所以有，$\\overline{x} - \\overline{y} \\sim N(\\mu_1 - \\mu_2, (1/m+1/n)\\sigma^2)$，标准化之后是有$\\sigma$的，但是通过下式，$\\frac{(m-1)s_x^2}{\\sigma^2}+ \\frac{(n-1)s_y^2}{\\sigma^2} =\\frac{(m-1)s_x^2+(n-1)s_y^2}{\\sigma^2}\\sim \\chi^2(m+n-2)$（卡方分布的可加性），将方差进行替换，得到一个 $t$ 分布（ $t$ 分布是标准正态分布除以根号下卡方分布除以自由度） 构造思路同上，最后保留 $\\sigma_1$，$\\frac{(m-1)s_x^2+(n-1)s_y^2/c}{\\sigma_1^2}\\sim \\chi^2(m+n-2)$，然后操作同上 因为基本上任何分布，样本量足够大的时候都朝着正态分布趋近 死记硬背吧，这个还在研究中 两个卡方分布变量$\\frac{(m-1)s_x^2}{\\sigma_1^2}\\sim \\chi^2(m-1)$、$\\frac{(n-1)s_y^2}{\\sigma_2^2}\\sim \\chi^2(n-1)$除以各自的自由度（$m-1$和$n-1$）后再相除是$F$分布 （4）正态总体参数的区间估计 一 二 三 4 假设检验 假设检验的基本原理源于“小概率事件”原理,是一种基于概率性质的反证法，其核心思想是小概率事件在一次试验中几乎不会发生。 （1）概念及基本步骤假设检验：针对总体参数提出一个假设，然后通过样本统计量进行检验 基本步骤： 建立假设（$H_0$ 和 $H_1$） 我们通常把无影响、没效果作为 $H_0$（除非有足够的理由证明发生了变化），$H_0$ 和 $H_1$都是基于总体参数的，而不是样本。思想是，通过样本检验总体假设是否正确。 选择检验统计量并给出拒绝域形式 参照区间估计枢轴量表格即可，要注意的是，检验统计量和枢轴量不同，检验统计量要把枢轴量里面的参数替换成检验值。比如说，在一次检验中，$H_0: \\mu_1 = \\mu_2$，选择枢轴量为$G = \\frac{\\overline{x} - \\overline{y} - (\\mu_1 - \\mu_2)}{\\sqrt{\\frac{\\sigma_1^2}{m} + \\frac{\\sigma_2^2}{n}}} \\sim N(0, 1)$ ，对应的检验统计量为$u = \\frac{\\overline{x} - \\overline{y}}{\\sqrt{\\frac{\\sigma_1^2}{m} + \\frac{\\sigma_2^2}{n}}} \\sim N(0, 1)$ ，其实就是说检验统计量不含有未知参数，必须是一个可以用样本计算的数。拒绝域的形式和备择假设方向一致， 原假设 备择假设 拒绝域形式 $\\mu_1 = \\mu_2$ $\\mu_1 \\not= \\mu_2$ $|u| \\geq u_0$ $\\mu \\geq \\mu_0$ $\\mu &lt; \\mu_0$ $u \\leq u_0$ … … … 选择显著性水平，给出拒绝域 确定了拒绝域 $W$ 的方向后，选择相应的显著性水平找出用于判断的临界值。常用的是 $\\alpha=0.05$ 作出判断，判断检验统计量是否在拒绝域内 （2）小概率事件的基本原理进行假设检验利用的是小概率原理，小概率原理是指发生概率很小的随机事件在一次试验中几乎不可能发生，但多次重复实验后必然发生。根据这一原理可以作出是否拒绝原假设的决定。但什么样的概率才算小呢？著名的英国统计学家费希尔把小概率的标准定为0.05，虽然费希尔并没有对为什么选择0.05给出充分的解释，但人们还是沿用了这个标准，把 0.05或比0.05更小的概率看成小概率。 （3）两类错误第 Ⅰ 类错误（$\\alpha$ 错误，弃真错误）：原假设为真，但是被拒绝 第 Ⅱ 类错误（$\\beta$ 错误，取伪错误）：原假设为伪，但没被拒绝 注：这里 $\\mu_0$ 是假设参数值。（a）是假设的统计量分布，（b）是实际的统计量分布。 （1）当 $H_0: \\mu = \\mu_0$ 为真时，如果 $\\mu$ 落入 $\\alpha$ 区域，那么就会出现第一类错误，拒绝了正确的假设，想要降低需要选择比较低的显著性水平 $\\alpha$ （2）当 $H_0: \\mu = \\mu_0$ 为伪时，比如实际上 $\\mu &gt; \\mu_0$，但是观测 $\\mu$ 落入了 $\\beta$ 区域，那么就会出现第二类错误，接受了错误的假设，想要降低需要选择比较低的 $\\beta$ 水平 第一类错误的概率就是最初假设的显著性水平：$\\alpha$ 第二类错误的概率需要计算，以上图为例，第二类错误的概率是 $\\mu$ 落入两条粉色线条中间区域的概率 $\\alpha$ 与 $\\beta$ 是在两个前提下的概率，所以 $\\alpha + \\beta$ 不一定等于 1 在其他条件不变的情况下，$\\alpha$ 与 $\\beta$ 不能同时增加或减少 样本量的增加能够在给定 $\\alpha$ 时减小 $\\beta$ （4）正态总体检验 均值检验：用 $z$ 统计量（已知方差）或者 $t$ 统计量（未知方差） 方差检验：用 $\\chi^2$ 统计量，$\\frac{(n-1)s^2}{\\sigma^2} \\sim \\chi^2(n-1)$ 两个正态总体（参考参数估计章节） （5）分布拟合检验用于测定两个分类变量的相关程度，用于检验样本数据是否来自某个特定的概率分布。 $\\chi^2 = \\sum\\limits_{i=1}^n \\frac{(f_{i,0} - f_{i,e})^2}{f_{i,e}} \\sim \\chi^2(n-1)$ 5 相关分析与回归分析（1）相关分析 相关图 相关系数 皮尔逊相关系数：$r = \\frac{\\sum(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum(x_i - \\bar{x})^2\\sum(y_i - \\bar{y})^2}}$ 相关系数的 $t$ 值：$t = \\frac{r \\sqrt{n-2}}{\\sqrt{1 - r^2}} \\sim t(n-2)$ 斯皮尔曼相关系数：$r_s=1-\\frac{6\\sum_{i=1}^nd_i^2}{n(n^2-1)}$，$d_i$ 代表等级差 （2）回归分析 回归形式： 一元：$Y_{i} = \\beta_0 + \\beta_1 X_i + \\varepsilon_{i}$ 假设 模型正确设立，总体回归模型是线性的 严格外生性：$\\mathbb{E}(\\varepsilon_i|{\\bf{X}}) = 0$ 不存在严格多重共线性，数据矩阵列满秩，$\\mathrm{rank}({\\bf{X}}) = m$ 球型干扰项，即 $Var(\\varepsilon_i | {\\bf{X}}) = \\mathbb{E}(\\varepsilon_i^2 | {\\bf{X}}) = \\sigma^2$，$cov(\\varepsilon_i,\\varepsilon_j) = \\mathbb{E}(\\varepsilon_i\\varepsilon_j) = 0,i\\not=j$ 推论 $\\mathbb{E}(\\varepsilon_i) = 0$ $cov(X_i, \\varepsilon_j) = \\mathbb{E}(X_i\\varepsilon_j) = 0$ $Var(\\varepsilon_i) = \\sigma^2$，用到方差分解原理：$\\mathrm{Var}(\\varepsilon)=\\mathbb{E}[\\mathrm{Var}(\\varepsilon|X)]+\\mathrm{Var}[\\mathbb{E}(\\varepsilon|X)]$ 最小二乘估计原理：最小化观测值与估计值的残差平方和 最小二乘参数估计方法 点估计 极大似然估计：最后发现依然是最小化残差平方和 矩估计： 两个条件 $\\mathbb{E}(\\varepsilon_i) = 0$ $cov(X_i, \\varepsilon_i) = \\mathbb{E}(X_i\\varepsilon_i) = 0$ 对应的矩条件 $\\frac{1}{n} \\sum (\\hat{Y} - \\hat{\\beta}_0-\\hat{\\beta}_1X_i) = 0$ $\\frac{1}{n} \\sum (\\hat{Y} - \\hat{\\beta}_0-\\hat{\\beta}_1X_i)X_i = 0$ 矩阵推导 常见的矩阵求导公式： 线性函数导数 $$\\frac{\\partial {\\bf{a}}’{\\bf{x}}}{\\partial {\\bf{x}}} = {\\bf{a}}$$ $$\\frac{\\partial {\\bf{A}}{\\bf{x}}}{\\partial {\\bf{x}}} = {\\bf{A}}$$ 二次型导数 $$\\frac{\\partial {\\bf{x}}’{\\bf{A}}{\\bf{x}}}{\\partial {\\bf{x}}} = ({\\bf{A}} + {\\bf{A}}’){\\bf{x}}$$ 矩阵的迹 $$\\frac{\\partial \\mathrm{tr}(\\bf{AX})}{\\partial {\\bf{X}}} = {\\bf{A}}’$$ 行列式导数 $$\\frac{\\partial \\det({\\bf{X}})}{\\partial {\\bf{X}}} = \\det({\\bf{X}})({\\bf{X}}^{-1})’$$ 对矩阵求导 $$\\frac{\\partial \\bf{a}’{\\bf{X}}{\\bf{X}}’{\\bf{b}}}{\\partial {\\bf{X}}} = \\frac{\\partial \\bf{a}’{\\bf{X}}’{\\bf{X}}{\\bf{b}}}{\\partial {\\bf{X}}} = ({\\bf{a}}{\\bf{b}}’ + {\\bf{b}}{\\bf{a}}’)X$$ 估计量的性质 BLUE（最佳线性无偏估计）：线性性（$\\beta$ 是 $Y_i$ 的线性组合）、无偏性（$\\mathbb{E}(\\hat{\\beta} | X) = \\beta$）、有效性（方差最小） 一元回归表达式： $\\hat{\\beta}_1 = \\sum k_iy_i = \\beta_1 + \\frac{\\sum x_i\\varepsilon_i}{\\sum x_i^2}$ $\\hat{\\beta}_0 = \\sum w_iy_i = \\beta_0 + \\sum(1/n + \\bar x k_i)\\varepsilon_i$ 矩阵形式：$\\hat{\\beta} = \\beta + \\mathbb{E}((X’X)^{-1}X’\\varepsilon)$ 期望、方差及其分布 $\\hat{\\beta}_1 \\sim N\\left( \\beta_1, \\frac{1}{\\sum (x_i - \\bar{x})^2} \\sigma^2 \\right)$ $\\hat{\\beta}_0 \\sim N\\left( \\beta_0, \\left( 1/n + \\frac{\\bar{x}^2}{\\sum (x_i - \\bar{x})^2} \\right) \\sigma^2 \\right)$ $\\hat{\\beta} \\sim N(\\beta, \\sigma^2(X’X)^{-1})$ 三个差平方和：SST = SSR + SSE 名称 形式 总离差平方和：SST $\\sum (y_i - \\bar{y})^2$ 回归平方和：SSR $\\sum (\\hat{y} - \\bar{y})^2$ 残差平方和：SSE $\\sum (y_i - \\hat{y})^2$ 拟合优度：$R^2 = \\frac{SSR}{SST}$ 显著性检验 回归系数的显著性检验：$t$ 检验，$\\frac{\\hat{\\beta}}{se(\\hat{\\beta})} \\sim t(n-k)$ 方程的显著性检验：$F$ 检验，$\\frac{SSR / (k-1)}{SSE / (n - k)} \\ \\sim F(k-1, n-k)$ 预测误差 $S_e = \\sqrt{\\frac{\\sum (y_i - \\hat{y})^2}{n - k}} = \\sqrt{\\frac{SSE}{n-k}}$ $\\hat{Y}_i \\sim \\left(\\beta_0 + \\beta_1 X_i, \\left( 1/n + \\frac{(x_i - \\bar{x})^2}{\\sum (x_i - \\bar{x})^2} \\right) \\sigma^2 \\right)$ 置信区间：$\\hat{y}_i \\pm t_{\\alpha / 2} \\left( 1/n + \\frac{(x_i - \\bar{x})^2}{\\sum (x_i - \\bar{x})^2} \\right) S_e $ ，可以得到 $\\mathbb{E}(y_i)$ 对应的置信区间 也有一些学者认为是 $\\hat{y}_i \\pm t_{\\alpha / 2} \\left(1 + 1/n + \\frac{(x_i - \\bar{x})^2}{\\sum (x_i - \\bar{x})^2} \\right) S_e $ （3）模型诊断 多重共线性 后果 参数估计量不存在：因为矩阵列不满秩，导致 $X’X$ 不可逆 估计量方差变大。当 $x_1, x_2$ 存在部分共线性时，方差膨胀因子为： $\\mathrm{VIF}(\\hat{\\beta}_1) = 1 / \\left(1-\\frac{(\\sum x_{i1}x_{i2})^{2}}{\\sum x_{i1}^{2}\\sum x_{i2}^{2}} \\right) = 1 / (1 - r_{12}^2)$ 参数估计量经济意义不合理：因为无法分离二者关系 变量显著性检验和模型预测功能失去意义：方差变大，导致 $t$ 值变小和预测区间变大 检验方法 相关系数矩阵：看一下解释变量之间的相关系数是否趋于 1 综合统计检验法：如果模型的 $R^2$ 和 $F$ 值较大，但是每个系数的 $t$ 值都比较小，说明联合显著，但是共线性的存在使得他们对 $Y$ 的独立作用无法分辨 判定系数法：使用变量 $x_j$ 对其他变量回归，作 $F$ 检验：$F_j = \\frac{R_j^2 / (k - 1)}{(1 - R_j^2) / (n - k)} \\sim F(k - 1, n - k)$，或者看 VIF 值，$\\mathrm{VIF} = \\frac{1}{1 - R_j^2}$，一般认为 VIF 大于 10 时存在严重的多重共线性问题 逐步回归法：逐个引入新变量，看 $R^2$ 的变化是否显著 解决方法 逐步回归剔除 LASSO 回归 岭回归 弹性网 主成分分析等方法降维 异方差问题 后果 参数估计量非有效：虽然仍然具有线性性与无偏性，但是不再具备有效性。即使是大样本晴空下，也不具有渐进有效性 变量的显著性检验失去意义：估计量方差发生变化，导致分布变化 模型预测失效 检验方法 图示法：使用残差平方与 $X$ 的图像分析 BP 检验：使用残差平方对 $X$ 回归，作 $F$ 或 $\\chi^2$ 检验： $F = \\frac{R_{e^2}^2 / (k - 1)}{(1 - R_{e^2}^2) / (n - k)} \\sim F(k - 1, n - k)$ $LM = n \\cdot R^2_{e^2} \\sim \\chi^2(k - 1)$ 怀特检验：类似 BP 检验，但是在回归时加入平方项和交互项 解决方法 加权最小二乘法 异方差稳健标准误 聚类稳健标准误 Driscoll-Kraay 标准误 Newey-West 回归 内生性问题 后果 参数估计量有偏、不一致且非有效（小样本有偏，大样本不一致） 变量显著性检验和模型预测功能失去意义 检验方法 豪斯曼检验 过度识别检验（如 Sargan 检验和 Hansen 检验，在使用多个工具变量，检验该组工具变量的外生性） 解决方法 增加控制变量：缓解遗漏变量问题 PSM、熵平衡、Heckman方法：缓解选择性偏误 工具变量法：缓解上述一系列问题和反向因果等 Oster 检验：验证遗漏因素对核心解释变量的影响不足以推翻原有结论 模型设定偏误 影响 参数估计量有偏、不一致且非有效（小样本有偏，大样本不一致） 方程不具有经济意义 变量显著性检验和模型预测功能失去意义 检验方法 检验是否包含无关变量：$t$ 检验 检验是否存在相关的遗漏变量：残差与 $X$ 的图示 一般性设定偏误检验：RESET 检验 解决方法 增加潜在的遗漏变量 更换模型形式，比如采用非线性模型 6 时间序列分析（1）时间序列分析概述时间序列是把同一现象在不同时间上的观察数据按时间先后顺序排列起来所形成的数列，也称动态数列。 时间序列的编制原则： 时间一致：分隔一致 总体范围一致 经济内容、计算口径和计算方法一致 （2）时间序列的水平分析与速度分析 水平分析 平均值：不同时点上的数据求平均值 增长量与平均增长量：包括逐期增量、累计增量、同比增量、平均增量 速度分析 发展速度：报告期水平 / 基期水平 环比发展速度（逐期发展速度） 定基发展速度（发展总速度） 增长速度：发展速度 - 1 平均发展速度和平均增长速度 （3）长期趋势和季节变动的测定 时间序列的构成 长期趋势 $T$ 季节变动（一年内所呈现的较有规律的周期性起伏波动） $S$ 循环变动（较长时间内呈现的涨落相同、峰谷交替的周期性波动） $C$ 不规则变动 $I$ 时间序列的分解 加法模型：$Y_t = T_t + S_t + C_t + I_t$ 乘法模型：$Y_t = T_t \\times S_t \\times C_t \\times I_t$ 长期趋势的测定方法 时距扩大法：通过合并消除掉季节波动和抵消不规则变动 移动平均法 趋势方程拟合法：线性趋势、非线性趋势 季节变动的测定 同期平均法：不同年份同个季度求平均 移动平均趋势剔除法 用移动平均值作为长期趋势值 用时间序列值减去或除以对应的长期趋势值 同期平均 调整指数：归一化处理 计量手段：滤波器或平滑方法提取趋势与周期性成分：BK滤波器、HP滤波器、HW平滑法等","link":"/2024/12/01/14-%E7%BB%9F%E8%AE%A1%E5%AD%A6/"},{"title":"黄达金融学笔记","text":"黄达金融学笔记 第一章 货币与货币制度货币职能 价值尺度：标价 价格指数与货币购买力成反比 交易媒介或流通手段：一手交钱，一手交货 必须使用现实的货币 可以足值可以不足值 支付手段：钱货分离（应收账款） 贮藏手段：退出流通领域 因为价值稳定：比特币从货币职能来看不是货币，因为不具备稳定的价值 （世界货币）：金银等具有实际价值的货币才有 货币制度 币材是一国货币制度最核心的问题 货币单位的确定 本币、辅币 铸币税 无限法偿、有限法偿 铸币税和通货膨胀税 货币的铸造成本低于其面值产生的差额 通货膨胀税是通货膨胀发生后，民众的货币购买力缩水，相当于变相的税收 无限法偿和有限法偿 无限法偿（一元及以上）：没有人不接受，不能拒绝 有限法偿（一元以下）：可以拒绝 格雷欣法则按照历史顺序：银 -&gt; 金银 -&gt; 金 -&gt; 纸 格雷欣法则：由于存在政府价格和市场价格，当两种价格不等时，必然会导致劣币驱逐良币 第二章 国际货币体系与汇率制度国际货币体系国家与国家之间的货币制度叫做国际货币体系/制度 特里芬难题：信心与清偿力的矛盾。由于美元与黄金挂钩，而其他国家的货币与美元挂钩，美元虽然取得了国际核心货币的地位，但是各国为了发展国际贸易，必须用美元作为结算与储备货币，这样就会导致流出美国的货币在海外不断沉淀，对美国来说就会发生长期贸易逆差；而美元作为国际货币核心的前提是必须保持美元币值稳定与坚挺，这又要求美国必须是一个长期贸易顺差国。这两个要求互相矛盾，因此是一个悖论。 汇率制度 固定汇率制度 货币局制度：盯着某一种强势货币，建立固定汇率 联系汇率制度（香港）：发行和货币局一样，流通领域汇率由市场供求决定 美元化：直接用美元作为流通货币 汇率分类 直接标价法（中国）和间接标价法（美国） 固定汇率（2005/7/21前）和浮动汇率 名义汇率和实际汇率 汇率的决定（重点） 金币本位制：铸币平价理论 汇率的最高点为黄金输出点：美国向英国输出黄金（铸币平价+运费） 汇率的最低点为黄金输入点：英国向美国输入黄金（铸币平价-运费） 金价比较稳定，汇率波动的情况下：假设运费为0.02美元 美国欠英国1英镑：美国人最大能接受的代价是(4.8666+0.02)美元=1英镑,汇率超过这个比值都用黄金交易算球，低于的话就在美国外汇市场换成英镑给她。 英国欠美国4.8665美元，英国人最大能接受的代价是1英镑+0.02美元=4.8665美元，汇率超过这个比值都用黄金交易，没超过英国老就在英国的外汇市场换成美元给美国人。 黄金输入输出点把汇率上下限锁定。 在这个区间不会由黄金的流动，双方国家更愿意采用外汇市场进行兑换，如果超出这个区间，他们就去黄金市场兑换。 国际借贷理论：汇率变动由外汇供求决定，受到国际商品进出口和国际资本流动引起的债权债务关系影响，也就是说由一套综合因素决定，如国内外国民收入、国内外价格水平、国内外利率水平、以及人们对未来汇率的预期值 短期内：收入↑ - 进口↑ - 本币贬值 购买力平价理论（适合解释中长期汇率）：绝对购买力（点）、相对购买力（时期） 利率平价理论：$F = Se^{(r_f - r_d)(T-t)}$，$S$ 是即期汇率（直接标价法），$F$ 是远期汇率。 人民币国际化：现在国际货币体系对发展中国家不利 最优货币区与欧元 由于区内商品劳务以及要素往来比较多，所以在区内采用固定汇率，区外采用浮动汇率 欧元不是经济学家说的最优货币区，把经济放在了政治前面 第三章 信用、利息与信用形式信用是以偿还为条件的价值单方面转移。 商业信用商业信用是企业在正常的经营活动和商品交易中由于延期付款或预付款项所形成的企业的信贷关系。 主要是发生在企业与企业之间 有严格的方向性，一般是上游企业向下游企业提供商业信用 商业票据 商业本票：债务人向债权人发出的支付承诺书 商业汇票：债权人向债务人发出的支付命令书，债务人承诺付款的手续叫做承兑 银行信用银行或者类似银行业务的其他非银行的金融机构，以货币形式提供给企业信用 以金融机构为媒介 借贷的对象是处于货币形态的资本 间接融资资金盈余者先将金融剩余存入金融中介机构，后者将分散的金融剩余集中起来后在发放贷款。 银行扮演信用中介 直接融资通过金融市场将资金盈余部门的剩余资金流入到资金短缺的部门。短缺部门通过发行股票和债券等金融工具筹集资金。 券商扮演信息中介 要大力发展直接融资 民间借贷 从需求供给分析 容易违约 规范发展 第四章 金融范畴的形成与发展金融体系的构成要素（五个要素） 由货币制度所规范的货币流通 金融机构：区分银行和非银行金融机构 金融市场 金融工具：信用关系的书面证明、债权债务的契约文书等，是金融机构中和金融市场上交易的对象 金融制度和调控机制 第五章 金融中介体系西方国家金融中介体系 中国的金融中心体系以中国人民银行为中心，国有银行为主体，多种金融机构并存，分业经营、分业监管的金融中介机构体系格局。 政策性银行与开发性金融机构 1994年成立三家政策性银行：国家开发银行、中国进出口银行和中国农业发展银行 2015年重申中国进出口银行、中国农业发展银行为政策性银行，国家开放银行定位为开放性金融机构 从一行三会（央行、证监会、银监会和保监会）到一委一行两会（国务院金融稳定发展委员会、央行、中国证监会和银保监会） 成立金融稳定与发展委员会原因：设立国务院金融稳定发展委员会，是为了强化中国人民银行宏观审慎管理和系统性风险防范职责，强化金融监管部门监管职责，确保金融安全与稳定发展。 (1)国际角度：从欧美国家经验来看，分业监管暴露出监管真空和监管失控问题，需要进行重大改革，如加强机构之间的统一和协调，监管重心从局部风险转移到系统性金融风险。 (2)国内角度：改革并完善适应金融市场发展的金融监管框架。 可扭转金融监管体制稳==各自为政、各自为战==局面，消除各种监管纷争，形成高度一致的金融监管力量，确保党中央、国务院各项金融政策正确贯彻落实到位，遏制各种金融乱象，推动金融业不断走向规范、健康发展之道。具体说有四方面作用： 首先，为我国金融监管改革确立了基本方向，使我国金融监管体制得到进一步完善，为防范化解金融风险提供了根本保障。 其次，国务院金融稳定发展委员会起到金融监管短板的纠偏功能，能有效消除分业监管方式存在金融监管盲点及监管套利现象。 再次，金融稳定委员会实际上对现有金融监管资源进行一次合理、有效的整合，能弥补“一行三会”相互间信息资源分割、监管协调不足等缺陷，使金融监管机构协调性增强，监管权威性、震慑力更强，能有效消除金融监管真空，使社会各种非法金融乱象无处遁形。 最后，进一步明确金融功能定位及其作用，督促金融业把服务重点和方向放在实体经济身上，推动金融资源不断脱虚向实，为我国经济走出低俗奠定坚实的金融基础。 银保监会合并原因：第一，银行保险业务交叉严重，监管机构重合度高，合并监管有利于防范系统性金融风险。第二，两者监管对象相似，监管理念规则趋同（资本约束监管)，合并乃顺应趋势。第三，规范间接融资渠道，发展直接融资。 合并影响： 第一，金融监管从机构向功能和行为方向发展，是为适应目前金融综合经营的形式，减少监管套利。 第二，打破了监管部门壁垒，对银行、保险中的所有机构、业务和产品，由一个监管机构实现穿透式监管，有助于提高监管的广度和深度，找到风险的源头，有针对性地制定防控风险的措施，实现监管的全覆盖。 第三，对于银行来说，上收了部分微观审慎权限，未来金融监管标准将更加统一，监管执行力进一步提高。 第四，对于保险来说，监管机构合并，有助于规范保险机构经营，回归保险属性。 国际金融机构体系 第六章 存款货币银行（商业银行）重点：分业经营与混业经营、存款保险制度 存款货币银行发源地：意大利 1694年英格兰银行的成立标志着现代银行制度的建立 商业银行的作用 充当信用中介 充当支付中介 变社会各阶层的储蓄和收入为资本 创造信用流通工具 存款货币银行的类型与组织 西方商业银行的类型 按照经营模式 职能分工型银行：美国、日本 全能型商业银行：德国、奥地利、瑞士 商业银行的组织制度 单元银行制度（单一银行制度）：业务只由一个独立的银行机构经营而不设立分支机构的银行组织制度。（美国） 总分行制度、分支行制度：银行在大城市设立总行，在各地普遍设立分支行并形成庞大银行网络的制度。（中国） 代理行制度：银行相互间签有代理协议，委托对方银行代办指定业务的制度。 银行控股公司制度：一家控股公司持有一家或多家银行的股份，或者是控股公司下设多个子公司的组织形式。 在美国，还存在连锁银行制度：两家以上商业银行受控于同一个人或同一集团，但又不以股权公司形式出现的制度。 分业经营与混合经营 分业经营是指对金融中介机构业务范围进行某种程度“分业”管制。 混业经营是指金融中介机构实行综合经营的金融制度。比如，银行、证券和保险之间的综合经营。 1929-1933年，美国大萧条，和银行混业有关系 1933年，美国出台《格拉斯-斯蒂格尔法》：分业 1999年，《金融服务现代化法案》：混业 -&gt; 2008年危机 2010年，《多德-弗兰克法案》，核心条款“沃尔克规则”要求禁止银行机构使用自有资金投资盈利，促使商业银行回归传统信贷中介功能。：分业 《商业银行法》：我国是分业 论述题：分业现状、混业趋势、建立对应监管模式 金融创新的类型 避免风险（贷款风险）的创新，资产证券化，ABS、MBS、SPV 技术进步推动的创新：计算机技术 规避行政管理的创新：自动转账制度ATS、可转让支付命令账户NOW（20世纪60年代后期出现，出现高通胀，Q条例，美国对存款利率有要求，很低） 金融创新的影响 使得金融工具多样化、灵活化。 使金融机构传统的分工格局被突破，彼此业务全面交叉。 使一些国家在既成事实面前被迫放宽某些金融行政管制或取消、修改一些法令法规。 增加了各国货币政策的复杂性。 可以有效地转移和分散既有金融风险，本身又有可能带来新的风险，并通过创新交易的高杠杆性被放大、强化，而后借助相互之间联系紧密的信息网络得以广泛扩散。 不良债权不良债权是指银行顾客无力按期、按量归还本息的贷款 贷款风险分类管理 正常 关注：有能力偿还，但存在可能影响其清偿力的不利因素 次级：借款人还款能力有明显问题，依靠其正常经营收入已无法保证按时足额偿还本息 可疑：借款人无法足额偿还本息，即使执行抵押、担保也肯定会有损失 损失：在采取所有可能的措施和一切必要的法律手段后，贷款仍无法收回或只能收回极少部分 存款保险制度由吸收存款的金融机构根据其吸收的存款数额，按规定的保费率向存款保险机构投保，当存款机构破产而无法满足存款人的提款要求时，由存款保险机构承担支付法定保证金的责任。 美国是世界上最早建立存款保险制度的国家，于20世纪30年代在大危机后建立了第一个正式的全国性存款保险制度。随后，许多国家也相继效仿。 利：(1)有利于保护众多的小储户、小投资者的利益。(2)降低挤兑和金融机构连锁倒闭的可能性。 弊：(1)诱导存款人。由于存款保险制度的存在，会使存款人过份依赖存款保险机构，而不关心银行的经营状况，诱导存款人对银行机构的风险掉以轻心，从而鼓励存款人将款项存入那些许诺给最高利息的金融机构，而对这些机构的管理水平和资金实力是否弱于它们的竞争对手并不十分关心。(2)鼓励银行铤而走险。存款保险制度刺激银行承受更多的风险，鼓励银行的冒险行为。银行自身的制定经营管理政策时，也倾向于将存款保险制度视为一个依赖因素，使银行敢于弥补较高的存款成本而在业务活动中冒更大的风险。因为它们知道，一旦遇到麻烦，存款保险机构会挽救它们。(3)延缓金融风险暴露的作用，容易被权力者利用，导致风险不断累积，由此加大了解决问题将要付出的代价。 2015年5月1号，我国正式实施存款保险制度。 2019年，中国人民银行出资设立存款保险基金管理有限责任公司。我国存款保险制度的建立将弱化银行体系特别是国有商业银行体系背后的国家隐性担保，促进中小银行的发展，并在制度上允许银行倒闭，改善银行市场结构。最多赔偿50w。 第七章 中央银行央行建立的必要性 银行券统一发行的需要 建立全国统一的清算机构的需要 为商业银行提供最后流动性支持的需要 代表政府意志对金融业实施监管、协调 1694年英格兰银行 中央银行的类型 一元式：只有一个央行 二元式：建立中央和地方两级相对独立的中央银行机构 复合中央银行制度（还做存贷款） 跨国中央银行制度（欧洲中央银行） 准中央银行（香港） 中央银行的职能 性质：管理金融事业的国家机关和特殊的金融机构 特征：不以盈利为目的；不经营普通银行业务；在制定和执行货币政策时，中央银行具有相对独立性 我国货币政策目标：保持货币币值的稳定（物价稳定、汇率稳定），并以此促进经济增长 职能 发行的银行：发行货币 银行的银行：集中存款准备金、最后贷款人、组织全国的清算 国家的银行：国家的银行是指中央银行代表国家贯彻执行财政金融政策，代理国库收支以及为国家提供各种金融服务。 代理国库 代理国家债券的发行 对国家财政给予信贷支持 保管外汇和黄金储备，进行外汇、黄金的买卖和管理 制定和实施货币政策制定并监督执行有关金融管理法规 中央银行的资产负债表（重点） 负债主要是指基础货币 = 通货 + 准备金 央行外汇和公开市场等操作都会导致资产负债同时增加和减少 中央银行的独立性问题是指货币政策的决策和运作方面，中央银行由法律赋予或实际拥有的自主程度 中央银行保持独立性的原因： 中央银行与政府所处地位、行为目标不尽相同 作为特殊的行政管理机构，中央银行运作需要具备必要的专业理论素养和较为长期的专业经验积累 中央银行对政府的独立性是相对的： 中央银行应当服从于经济社会大系统的运转，服从于国家的根本利益 货币政策目标的实现需要其他政策特别是财政政策的协调与配合 中央银行在履行自己的职责时，需要政府其他部门的协作与配合 中国的中央银行独立性问题中国人民银行==在国务院领导下==依法独立执行货币政策，履行职责，开展业务，不受地方政府、各级政府部门、社会团体和个人的干涉。 中国人民银行就年度货币供应量、利率、汇率和国务院规定的其他重要事项作出的决定，报国务院批准后执行。 中国人民银行不得对政府财政透支，不得直接认购、包销国债和其他政府债券。（不允许财政赤字货币化） 财政赤字货币化政府发债 -&gt; 央行购入（中国不能买） -&gt; 增发货币、通货膨胀 第八章 金融市场 这部分其实讲了货币市场和金融衍生品市场 金融市场及金融资产资金供求双方借助金融工具进行各种资金交易活动的场所 两个重要功能： 帮助资金和资源进行重新分配 在资金重新分配过程中，帮助分散和转移风险 金融资产的特征： 货币性：可以作为货币或者转换成货币 流动性 偿还期限：在进行最终支付前的市场长度 风险性：信用风险、市场风险（价格下跌的风险） 收益性： 名义收益率：票面收益 / 票面面值 现时收益率：票面收益 / 市场价格 实际收益率：（现时收益 + 资本损益（年金））/ 市场价格 12&gt;&gt;&gt; 5/(1.08 + 1.08**2 + 1.08**3 + 1.08**4 + 1.08**5 + 1.08**6 + 1.08**7 + 1.08**8 + 1.08**9)0.37073939431479047 当期收益率：债券年利息 / 市场价格，其实就是现时收益率 到期收益率：使某项投资或金融工具未来所有收益的现值等于当前价格的利率 金融市场的功能 帮助实现资金在资金盈余部门和资金短缺部门之间的调剂，实现资源配置。 实现风险分散和风险转移。 确定价格。 发挥提供流动性的功能。 降低交易的搜寻成本和信息成本。 金融市场的类型 货币市场 票据市场与贴现市场：商业票据、银行票据、中央银行票据 国库券市场 可转让大额订单市场 回购市场 银行间拆借市场 贴现：资金需求方与商业银行之间 转贴现：商业银行之间 再贴现：商业银行与中央银行 中央银行票据 中央银行向商业银行发行的短期债务凭证，其目的是调节商业银行的超额准备金 贴现率是假设以平价发行的收益率，实际收益率则是以实际价格计算 逆回购会释放流动性 银行拆借市场主要是用于商业银行的存款准备金，以联邦基金利率计算 衍生工具市场 远期 / 期货 $$F = Se^{r(T - t)}$$ 远期合约：双方约定在未来某一时间，按照某一价格交易一定数量的标的物。 远期利率的合约金是结算时银行支付给企业超出或低于约定利率所产生的额外利息部分，以未来利率计算折现得到的本金增加或减少。 期权 对于欧式看涨期权：$$c_t = S_tN(d_1) - Xe^{-r(T - t)}N(d_2)$$对于欧式看跌期权： 互换 投资基金投资基金是一种利益共享、风险共担的集合投资制度 契约型基金是根据一定的信托契约原理组建的代理投资制度。委托者、受托者和受益者三方订立契约，由经理机构（委托者）经营信托资产；银行或信托公司（受托者）保管信托资产；投资人(受益人)享有投资收益。——私募基金一种 公司型基金是按照股份公司方式运营的。投资者购买公司股票成为公司股东。公司型基金涉及四个当事人：投资公司，是公司型基金的主体；管理公司，为投资公司经营资产；保管公司，为投资公司保管资产，一般由银行或信托公司担任；承销公司，负责推销和回购公司股票。 开放式基金和封闭式基金 对冲基金 货币市场基金：投资于货币市场金融产品的基金，如商业票据、银行承兑汇票、可转让大额定期存单及其他短期类票据的买卖 中国外汇市场 客户与外汇指定银行之间的零售市场，又称银行结售汇市场 银行之间买卖外汇的同业市场，又称银行间外汇市场 欧洲货币市场欧洲美元 —— 存在美国领土之外的美元 欧洲货币市场是一个完全自由的国际金融市场。其特点有： 经营自由，一般不受所在国管制； 资金来自世界各地，各种主要可兑换货币都有交易，而且规模庞大，能满足各种筹资需要； 存款利率相对高，贷款利率相对低，利差经常在0.5%左右,对存款方和贷款方都有吸引力； 借款条件灵活，不限贷款用途，手续简便。 第九章 资本市场股票市场英国最先成立 我国股票不能折价发行 风险投资投资过程 交易发起：风险资本金获知潜在的投资机会 筛选投资机会 评价：对选定项目的潜在风险与收益进行评估 交易设计：确定投资的数量、形式和价格等 投资后管理 初级市场与二级市场前者是发行的市场，后者是交易的市场 第十章 金融体系结构金融体系与金融功能金融市场是直接融资领域，金融中介是间接融资领域 金融系统功能 在时间和空间上转移资源 提供分散、转移和管理风险的途径 提供清算和结算的途径，以完结产品、服务和各种资产的交易 提供了集中资本和股份分割的机制 提供价格信息 提供解决“激励”问题的方法 金融体系的两种结构 美国的金融体系，资本市场非常发达；在欧洲很多国家，例如德国和法国，则是大银行在金融体系中占据主导地位。 中国的金融体系，静态观察，银行占绝对优势；动态观察，资本市场发展迅速。 由于近年来信息技术的发展，金融中介降低信息成本的作用急剧下降 由于信息技术的影响，资本市场的功能得到极大的强化 降低了以银行为代表的传统金融中介机构市场准入的门槛 互联网金融互联网金融：传统金融机构与互联网企业利用互联网技术和信息通信技术实现资金融通、支付、投资和信息中介服务的新型金融业务模式。 特征： 成本较低 效率较高 服务面广 风险较大 管理较难 第十一章 金融基础设施狭义：以中央银行为主体的支付清算体系 广义：还包括确保金融市场有效运行的法律程序、会计与审计体系、信用评级、监管框架以及相应的金融标准与交易规则等 清算方式 全额实时计算 净额批量结算 大额资金转账系统 小额定时结算系统（零售支付系统） 第十二章 货币政策与货币均衡 全是重点，开始都是重点 利率及其种类 基准利率（比如联邦基金利率）与无风险利率：利率 = 机会成本补偿水平 + 风险溢价水平 实际利率与名义利率 实际利率：物价水平不变，货币购买力不变条件下的利率水平 名义利率：包括补偿通货膨胀（或通货紧缩）风险的利率 $1 + r = {1 + i \\over 1 + \\pi^e}$ =&gt; $i = r + \\pi^e$ 短期，长期实际利率相对固定，名义利率 $i$ 与通胀率 $\\pi^e$ 一一对应（费雪效应，古典学派） 市场利率、官方利率、行业利率 年率、月率、日率 利率的决定 马克思的利率决定论 马克思认为，利息是贷出资本的资本家从借入资本的资本家那里分割出来的一部分剩余价值，利润是剩余价值的转化形式。利率的变化范围一般在零与平均利润率之间。在平均利润率与零之间，利率的高低取决于两个因素：一是利润率；二是总利润在贷款人和借款人之间进行分配的比例。 古典学派利率决定论（实际利率理论） 由投资 $I$ 和储蓄 $S$ （收入剔除消费的部分）共同决定 凯恩斯利率决定论 认为短期利率由货币供应量和对货币的需求量所决定 但是凯恩斯认为货币供给由央行决定，但其实是有问题的$${M \\over P} = L(i, Y)$$ 可贷资金论（综合理论） 不是一般均衡，因为无法保证产品市场均衡。 IS-LM（新古典综合理论） IS曲线（$I = S$）：$$S = Y - C(Y) = -\\alpha + (1-\\beta)Y$$ $$I = e - dr$$ $$Y = {\\alpha + e - dr \\over 1 - \\beta}$$ LM曲线$${M \\over P} = L(r, Y) = kY -hr$$ $$Y = {M/P + hr \\over k}$$ 影响利率的风险因素 通货膨胀风险 违约风险 流动性风险 偿还期限风险 我国利率市场化进程 LPR：贷款市场报价利率，才是改革的核心方式，贷款基准利率 MLF：中期借贷便利 利率的作用 储蓄的利率弹性：替代效应（更少消费）和收入效应（收入多了更多消费） 利率发挥作用的环境与条件：利率提供有利的价格信息 第十三章 货币需求货币需求理论的发展 费雪方程式与剑桥方程式 费雪方程式：$MV = PY \\Rightarrow M = {PY \\over V}$，强调交易媒介 剑桥学派：$M_d = kPY$，$k$ 为以货币形态保有财富占名义总收入的比例，强调货币是一种资产 凯恩斯的货币需求分析 凯恩斯货币需求理论：交易动机、预防动机、投机动机，研究资产时只考虑了货币与债券 $M = L_1(Y) + L_2(r)$，前者是交易动机和预防动机，后者是投机动机 流动性陷阱：货币需求变成水平线，利率很低时，货币需求无穷大，货币政策失效 后凯恩斯学派对货币需求理论的发展 鲍莫尔-托宾模型：$L = {Y \\over 2N} = \\sqrt{YF \\over 2r}$，认为交易动机也和利率相关 预防性货币需求的发展：$M = \\left( 2S^2z \\over r \\right)^{1 \\over 3}$ 弗里德曼货币需求函数（广义货币，包括股票等） ${M_d \\over P} = f\\left( y, w, r_n, r_b, r_c, {1\\over P } \\times {dP \\over dt}, u \\right)$ 恒久性收入 $y$，（主要因素，稳定因素） 非人力财富占个人总财富比率 $w$ 机会成本变量 代表多种因素的综合变数 $u$ 恒久收入的稳定性决定了货币需求的稳定性 总结 观察的货币口径逐步由窄到宽 视角出发点从宏观总量到微观行为主体的动机 货币职能不断拓宽 货币需求的决定因素向着广泛而深入的方向发展 第十四章 现代货币的创造机制 货币供给的决定 存款的创造 最终创造：$100 / 0.02 = 500w$ 货币创造乘数 不考虑定期存款、超额准备金、现金漏出的情形 活期存款乘数为：$$K = {\\Delta D \\over \\Delta R} = {1 \\over r_d}$$货币乘数为：$$m = {\\Delta D \\over \\Delta R} = {1 \\over r_d}$$ 考虑定期存款 活期存款乘数为：$$K = {\\Delta D \\over \\Delta R} = {1 \\over r_d + t \\times r_t}$$货币乘数为：$$m = {\\Delta D + \\Delta T \\over \\Delta R} = {1 + t \\over r_d + t \\times r_t}$$ 考虑所有 活期存款乘数为：$$K = {\\Delta D \\over \\Delta R} = {1 \\over r_d + r_e + r_c + t \\times r_t}$$货币乘数为：$$m = {\\Delta D + \\Delta T + \\Delta C \\over \\Delta C + \\Delta R} = {1 + t + r_c \\over r_d + r_e + r_c + t \\times r_t}$$ 中央银行角度 $$M = m \\times B$$ $B$：基础货币 高能货币 铸币税货币铸造成本低于其面值而产生的差额。 货币乘数与大萧条 弗里德曼观点 通货-存款比上升 超额准备金率增加 第十五章 货币供给货币供给及其口径按照流动性划分 符号 定义 $M_0$ 流通中的现金 $M_1$ $M_0$+企业活期存款+机关团体存款+农村存款+个人持有的信用类存款 $M_2$ $M_1$+城乡居民储蓄存款+企业存款中具有定期性质的存款+外币存款+信托类存款+证券客户保证金+住房公积金中心存款+非存款类金融机构在存款类金融机构的存款 $M_3$ $M_2$+金融债券+商业票据+大额可转让存单等 准货币：$M_2 - M_1$ 剪刀差：${\\Delta M_1 \\over M_1} - {\\Delta M_2 \\over M_2}$ 大也不一定是好事，因为企业存款增加可能是对经济悲观。 经济主体行为与货币供给 货币当局：影响基础货币与货币乘数 居民持币行为：通货-存款比 企业行为：存款需求 存款货币银行行为：超额准备金率和想中央银行借款的规模 影响通货-存款比的主要因素： 财富效应：存款增加比通货快，导致通货存款比下降 预期报酬率变动效应：储蓄利率增加、其他资产收益增加 金融危机：大量取款 非法经济活动逃避法律监督，倾向于现金交易 外生变量还是内生变量 “货币供给是外生变量”，含义是：货币供给并不是由经济因素，如收入、储蓄、投资、消费等因素所决定的，而是由货币当局的货币政策决定的。 “货币供给是内生变量”，含义是：货币供给的变动，货币当局的操作起不了决定性的作用，起决定作用的是经济体系中实际变量以及微观主体的经济行为等因素。 对货币政策有效性有影响。 “超额”货币及其反映的规律$$\\frac{\\Delta M}{M} + \\frac{\\Delta V}{V} = \\frac{\\Delta P}{P} + \\frac{\\Delta Y}{Y}$$ 我国以M2衡量的货币增长速度经常超过经济增长速度与通货膨胀率之和： 价格指数和产出水平被低估 经济商品化的程度偏低 普遍规律，即其他国家也遇到过发展过程中有货币超额现象 货币流动速度减缓 第十六章 货币均衡与总供求 本质上是 AD-AS 模型 第十七章 开放经济的均衡 国际收支平衡表编制原则贷方 - 借方 &gt; 0：顺差 贷方 - 借方 &lt; 0：逆差 贷方记录的是资金的来源，如货物、劳务的出口（向国外提供实际资产)和资产流入（本国对外金融资产的减少或本国对外负债的增加） 借方记录的是资金的使用，如货物、劳务的进口（从国外取得实际资产)和资本流出（本国对外金融资产的增加或本国对外负债的减少）。 官方储备增加记在借方，是因为反映了个体将外汇转换为本币的资金运用行为；记在贷方则表示官方储备的减少，反映了个体或央行将外汇储备作为资金来源进行购买或者公开操作。 国际收支项目 初次收入：国外打工获得的收入和投资收益（不算入资本利得） 二次收入：经常转移，不以获取收入或者支出为目的的单方面交易行为（但不包括资本性质的无偿转移） 国际收支的调节国际收支平衡表上的各个项目，可区分为自主性交易和调节性交易。自主性交易由生产经营、单方面支付和投资的需要所引起的交易；调节性交易是因为国际收支其他项目出现差额需要弥补，才相应发生的交易。判断一国国际收支是否平衡，主要是看其自主性交易是否平衡。如果必须依靠调节性交易平衡自主性交易的差额，则为国际收支失衡。 国际收支失衡的原因： 受经济发展阶段的影响：如前期需要进口大量技术等； 受经济结构制约； 受物价和币值的影响； 受汇率变化的影响； 受利率变化的影响——资金流动的角度； 受经济周期变化的影响——分繁荣和萧条。 国际收支调节的方式 财政政策 汇率政策 利率政策 利用政府信贷和国际金融机构的贷款 实行外汇管理 加强国际经济合作 国际储备包括外汇储备 国际储备是一国或地区官方拥有的、可以随时使用的并为世界各国所普遍接受的资产。主要作用是应付国际收支失衡、维持汇率稳定。 国际储备资产的构成： 货币当局持有的黄金（黄金储备） 在IMF的储备头寸，即普通提款权 特别提款权 外汇储备 外汇储备： 外汇储备不是越多越好，会增加对市场均衡的压力，等价于持有外币金融债权，会因为外汇贬值而蒙受巨额损失 保持适度的外汇储备水平应考虑的因素：适度的外汇储备水平，取决于经济发展的规模和速度、对外开放的程度、以及国家影响国际收支的有效程度等因素 管理原则： 考虑资金安全 保持流动性，灵活变现 投资于稳定成长的证券，获取收益 外债是指一切本国居民对非居民承担的、契约性的、以外国货币或者本国货币为核算单位的、有偿还义务的负债。 对外借款、发行外币债券是典型的外债。 马歇尔-勒纳条件与J曲线马歇尔一勒纳条件的结论是，当进口需求的价格弹性和出口需求的价格弹性之和大于1时，本币贬值可改善国际收支（原逆差）。 第十八章 通货膨胀与通货紧缩通货膨胀是商品和劳务的货币价格总水平持续明显上涨的现象。 CPI（$\\frac{\\sum P_1 Q_0}{P_0 Q_0}$）、批发物价指数、GDP平减指数（$\\frac{\\sum P_1 Q_1}{P_0 Q_1}$） 通货膨胀的原因 需求拉上说 成本推动说：工资推进型、利润推进型 供求混合推动说 通货膨胀的社会经济效应 强制储蓄效应 通货膨胀时，如果公众名义收入不变，实际收入就要降低，从而公众方面的实际诮费与实际投资可能减少（如果公众还只关注名义消费与名义投资，并且不愿意随着通货膨胀做出改变)，这样从全社会讲，公众方面相当于被动地进行了某种储蓄。 在经济处于充分就业状态时，通货膨胀的这种“强制储蓄效应”（如果政府发动通货膨胀且存在这种效应)相当于政府的挤出效应，政府的消费与投资替代（挤掉）了公众的消费与投资。或者说，==公众降低消费及投资引起的储蓄，被政府用于消费及投资了。== 收入分配效应 资产结构调整效应：财富分配效应 比价的变动与不同经济集团利益的调整 恶性通货膨胀与经济社会危机 通货膨胀与经济增长促进论、促退论和中性论 借助菲利普斯曲线理解 指数化和围绕指数化问题的讨论 收入指数化，随着物价变动 包括工资、政府债券和其他货币性收入 指数化措施主要有三个功效： 一是能借此剥夺政府从通货膨胀中所获得的收益，杜绝其制造通货膨胀的动机； 二是可以借此抵消或缓解物价波动对个人收入水平的影响，克服由通货膨胀造成的分配不公； 三是借此还可以稳定通货膨胀环境下的微观主体行为，避免出现抢购商品、储物保值等加剧通货膨胀的行为。 否定指数化方案的意见 (1)全面实行收入指数化会提出很高的技术性要求，因此任何政府都难以实施包罗万象的指数化政策； (2)收入指数化会造成工资一物价的螺旋上升，进一步加剧通货膨胀。 通货紧缩的经济社会效应 通货紧缩对投资的影响：不利于投资。 通货紧缩对消费的影响：价格效应（缩减消费）、收入效应（缩减支出） 通货紧缩对收入再分配的影响：与通货膨张刚好相反。 通货紧缩对工资的影响：工资会下降，但一般具有刚性。 通货紧缩与经济成长：一般来说，物价疲软与经济成长乏力结合在一起。 第十九章 货币政策货币政策及其目标狭义的货币政策：中央银行为实现给定的经济目标，运用各种工具调节货币供给和利率所采取的方针和措施的总和。货币政策和财政政策都属于需求管理政策。 宏观经济政策最终目标：充分就业、物价稳定、经济增长、国际收支平衡。 与财政政策都属于需求管理政策。 ==我国多重目标：== 保持币值稳定 并以此促进经济增长 我国“双支柱”调控框架： 健全货币政策与宏观审慎政策双支柱调控框架 “双支柱”调控框架旨在通过货币政策与宏观审慎的相互配合，兼顾币值稳定和金融稳定的双重目标 相机抉择和规则凯恩斯学派——“相机抉择”：反周期货币政策，经济趋热，相应紧缩；经济趋冷，相应扩张。（时间不一致性，为了短期牺牲长期） 货币主义主张货币政策应该遵循固定的货币增长率的规则。对于这种主张，概括为“单一规则”，以区别于“相机抉择”。 单一规则（货币学派，弗里德曼） 通货膨胀目标制：把通胀作为首要或唯一目标 泰勒规则 $r = \\pi + r^* + \\alpha \\left(\\pi - \\pi^* \\right) + \\beta y$ 理性预期学派认为，公众依据预期，采取相应行动，会使政策不能实现预定的目标。这就是政策无效命题。 货币政策工具 一般性政策工具 公开市场业务 再贴现政策 法定准备金率 选择性货币政策工具 直接信用控制 间接信用控制 补充工具： 常备借贷便利 SLF 中期借贷便利 MLF 定向中期借贷便利 LMLF 社会融资规模（考虑 M2） 货币政策的传导机制和中介指标 凯恩斯学派的货币政策传导机制理论，利率 托宾的Q理论，M↑ - PE↑ - 重置投资 I↑ - E↑ - Y↑ 货币学派的货币政策传导机制理论，M - Y 信贷传导机制理论，信贷减少，投资，Y 财富传导机制，M - P_E - W - C - E - Y 开放经济下的货币传导机制，M - 贬值 - NX - E - Y 货币政策中介指标的选择中介指标应具有： 可控性 可测性 相关性 抗干扰性 与经济体制、金融体制有较好的适应性。 中介指标一般有利率、货币供应量、超额准备金和基础货币等。 利率指标优点：(1)可控性强(2)可测性强(3)能够通过利率影响投资和消费支出，从而调节总供求。 利率指标缺点：利率作为内生变量或政策变量很难区分。 利率走廊： 货币供应量与利率对比选择： 只能二选一 货币供应量为数量型指标，利率为价格型指标 未来趋势：利率市场化改革 影响货币政策效应的因素 货币政策的时滞（内部时滞（认识时滞，行动时滞），外部时滞（操作时滞，市场时滞），后者更长） 货币流通速度 微观主体预期的抵消作用 透明度和取信于公众问题 其他经济政治因素 “稳健中性”的货币政策 “不紧不松”的中性态势 在不同的宏观经济形势下，政策的实际情况有差异 第二十章 货币政策与财政政策的配合与 IS - LM 模型相关 财政赤字和基础货币 增加税收：降低新投资的积极性和对贷款的需求 增发政府债券：不增加货币供给 变动基础货币：增加货币 财政赤字货币化：政府赤字 - 发债 - 央行购买 - 通货膨胀 国际通常采用的国债发行警戒线 货币政策与财政政策的组合IS-LM 分析短期，AD-AS分析长期（长期总产出由总供给决定） IS-LM分析中国经济的适用性： 货币需求的利率弹性较小 利率对于投资支出难以产生有效的调节作用 热点课模板：背景 - 对策 - 对策效果 财政政策：税收、转移支付这两个是通过影响可支配收入影响产出，政府购买直接影响产出 第二十一章 开放经济下的政策搭配与协调汇率的作用 汇率与进出口 贬值增加净出口，升值减少净出口。 汇率与物价 贬值，进口物价上升。 汇率与资本流出入 贬值，短期资本外流 汇率与产出和就业 相关关系是间接的，不能简单做判断 汇率风险进出口贸易风险 外汇储备风险 外债风险 大宗商品风险 汇率政策 米德冲突 米德认为，在==固定汇率制==下，政府无法运用汇率政策手段调控国内外需求，只能运用影响国内总需求的政策手段来平衡内外收支，宏观调控难以内外均衡兼顾，产生内外均衡的冲突。 米德冲突：政府在追求内部（外部）均衡时对总需求的调控措施使外部（内部）均衡状况恶化，距离目标更远。 蒙代尔政策搭配理论 克鲁格曼三角形 开放条件下的货币政策的国际传导 “美德两难”与东亚美元本位又叫“高储蓄两难” - 双循环 若让本币升值，升值会导致经济增长减速。 若让本币不升值，可能面临外部贸易制裁，恶化对外经济环境。 IS-LM-BP 模型 浮动汇率下，汇率的上升导致净出口减少，IS曲线回来 第二十二章 利率的风险结构与期限结构货币的时间价值现在的一块钱比未来的一块钱更有价值 利率的风险结构为什么国债利率更低？ 违约因素（用 P 与 r 反向变动分析） 流动性因素 税收因素（美国地方债免税） 利率的期限结构在其他条件相同的情况下，期限不同的证券之间存在利率差异。 到期收益率： 单利：到期收益率 = （票面利息（加减）本金损益）/ 市场价格 复利：内部收益率 利率期限结构理论： （纯）预期理论：对远期利率的行为有共同假设：都同意预期未来短期利率或远期利率的变化方向决定收益率曲线的形状；假定当前长期债券中的远期利率与市场对未来短期利率的预期有紧密联系。（对长短期不在乎） 流动性理论：投资者介意风险，要求获得流动性风险补偿。 市场分割理论：将不同到期期限的债券市场看作完全独立和相互分割的。到期期限不同的每种债券的利率取决于该债券的供给与需求。 第二十三章 资产组合与资产定价 看公司理财和投资学 金融市场风险类型 市场风险 信用风险 流动性风险：市场流动性不足；金融交易者流动性不足（银行挤兑） 操作风险 法律风险 政策风险 道德风险 逆向选择和道德风险 逆向选择：拥有信息优势的一方，在交易中总是趋向于做出尽可能地有利于自己而不利于别人的选择。 区别：逆向选择发生在交易之前，信息占优势的一方隐藏了信息；道德风险发生在交易之后，一方改变了自己的行为。 相关知识点 马科维茨的“均值-方差理论” 资本资产定价模型 $R_\\sigma = r_f + \\beta (R_m - r_f)$ 期权定价模型：投资学内容 第二十四章 资本结构与公司治理 属于公司理财内容 融资方式 间接融资和直接融资：区别在于金融中介的角色（信息中介还是信用中介？） 内源融资和外源融资：留存收益投资是最常见的内源融资方式，外源包括直接和间接 权益融资和债务融资 融资成本 加权平均成本 破产成本：直接和间接 直接：公司破产清算所发生的各种费用 间接：企业在面临财务危机时因经营过程受到影响所造成的损失 代理成本：因企业的委托人和代理人之间的代理问题所产生的成本 核心的资本结构理论 无税的MM定理：公司的资本结构不影响公司价值 有税的MM定理：由于债务融资有税盾，负债比重越大，公司价值越大 权衡理论：权衡抵税和破产风险 啄序理论：优序融资理论：内部融资 - 负债融资 - 权益融资 公司治理公司治理旨在营造一个讲求信用、高度透明和问责明确的环境，从而使公司能够获得长期投资、金融稳定和商业诚信，进而支持更强劲的公司增值和更具包容性的社会。 外部控制模式：“英美模式”或“用脚投票”控制模式，所有权分散，股东不能有效参与内部治理，主要依靠外部因素对管理层实行控制 内部控制投票：“德日模式”或“用手投票”控制模式，所有权较为集中，银行在公司治理中发挥了重要作用以及特别强调内部控制等 家族控制模式 转型治理模式：实行中央计划经济体制国家的企业在向市场经济体制转型过程中形成的特殊治理安排。最大问题：内部人控制，国企-&gt;私企 第二十五章 商业银行业务与管理 重要 商业银行的负债业务、资产业务 负债业务 负债业务：形成商业银行资金来源的业务。 全部资金来源包括自有资金和吸收外来资金两部分。 自有资金（统称权益资本）包括：成立时发行股票所筹集的股份资本，公积金和未分配的利润。 外来资金的形成渠道主要是：吸收存款、从中央银行借款、银行从业拆借、从国际货币市场借款、结算过程中的短期资金占用、发行金融债券、发行永续债。 资产业务 贴现 贷款 证券投资 租赁业务 中间业务与表外业务中间业务也称无风险业务：银行并不需要运用自己的资金而代理客户承办支付和其他委托事项，并据以收取手续费的业务。最常见的是传统的汇兑、代收、代客买卖等业务。 表外业务：凡未列入银行资产负债表内且不影响资产负债总额的业务。广义的表外业务既包括传统的中间业务，又包括金融创新中产生的一些有风险的业务，如互换、期权、期货、远期利率协议、票据发行便利、贷款承诺、备用信用证等业务。 商业银行的经营原则与管理经营原则： 盈利性 流动性 安全性 三原则既有统一的一面，又有矛盾的一面。安全性与流动性是相关的，它们与盈利性往往有矛盾 资产管理与负债管理： 资产管理 该理论的三个发展阶段： 商业贷款理论（真实票据论）：贷款短期和商业性 可转换性理论：资金一部分投资于具备转让条件的证券上 预期收入理论：贷款取决于未来收入 负债管理 资产负债综合管理 利率风险管理： 利率敏感性缺口管理：利率变动对银行净利润的影响 持续期缺口管理（久期缺口）：利率变动对银行权益的影响 部分符号说明：$$D_{gap} = D_A - D_L \\times \\frac{P_L}{P_A}$$市场变化值为：$$\\Delta P_E = (-\\Delta r) \\times \\frac{1}{1+r}P_A D_{gap}$$ 在险价值 —— VaR 技术VaR 即在险价值：一种用标准统计技术估计金融风险的方法。它是一种可以在正常的市场环境下，给定一定的时间区间和置信度水平，预计某种资产或资产组合最大损失的方法。 适用范围：适用于复杂的投资组合，用来说明投资的杠杆作用和分散的效果。 特点：可用表述潜在风险的数值简单明了的指示风险大小；计算VAR值的过程表明风险来源，指明了管理风险的着手点，可以辅助决策。 局限性：VAR表明的是一定置信度内的最大损失，但并不能绝对排除发生高过这个损失的可能性；只是一个工具，不能代替好的管理经验和判断，不具备决策的品格。 第二十六章 货币经济与实体经济 本质上在研究货币到底是中性还是非中性的 货币中性：货币数量的变动仅导致名义变量的变动，不会导致实际变量的变动。 货币非中性：货币数量的变动导致实际变量的变动。 长短期分析方法：短期货币是非中性的（IS-LM），长期货币是中性的（AD-AS） 长期达到均衡时，货币政策才是无效的。 第二十七章 金融发展与经济增长金融发展的含义 衡量金融发展结构指标 金融内部结构指标 主要金融资产占全部金融资产的比重。 金融机构发行的金融工具与非金融机构发行的金融工具的比率。 金融机构在非金融机构发行的主要金融工具中持有的比重。 主要金融机构相对规模。 各类金融机构的资产之和与占全部金融机构总资产的单独比率。 非金融部门的内源融资与外源融资之比。 国内金融机构和外国贷款人在各类债券和股票中的相对规模。 金融发展与经济增长的相互关系指标 金融相关率：某时期一国全部金融资产价值与该国经济活动总量(GDP)的比值。 货币化率：一国通过货币进行交换的商品与服务的值占国民生产总值之比。 货币化路径的“倒 U ”假说： 在金融深化的过程中，货币化率（一国通过货币进行交换的商品和服务的值占国民生产总值的比重）一开始呈现上升趋势，之后逐渐回落（货币化经济让位于“金融化”经济）。 金融压抑与经济增长 金融压抑 发展中国家存在的市场机制作用没有充分发挥、金融资产单调、金融形式单一、过多的金融监管和金融效率低下等现象。 发展中国家普遍存在的金融压抑现象 发展中国家的金融工具形式单一，规模有限。 存在着明显的“二元结构”：一是以大城市和经济发达地区为中心的由现代大银行为代表的现代部门；二是以落后的农村为中心的由钱庄、当铺为代表的传统部门。 发展中国家的金融机构单一，商业银行在金融活动中居于绝对的主导地位，金融机构的专业化程度低，金融效率低。 发展中国家的直接融资市场极其落后，并且主要是作为政府融资的工具而存在；企业的资金来源主要靠自我积累和银行贷款。 由于发展中国家实行严格的管制，致使金融资产价格严重扭曲，无法反映资源的相对稀缺性，具体表现是压低实际利率，高估本国货币的币值。（利率市场化不完全，本币币值更高才有利于进口） 金融压抑的政策原因 人为压低实际利率 采取信贷配给方式分配信贷资金 对金融机构实施严格控制 人为高估本币汇率——降低进口设备成本 利率管制对经济发展的负作用 低利率促使人们更关心现期消费，忽视未来消费，导致储蓄的低水平；（民众不爱储蓄） 低利率使潜在的资金供给者不去正规的金融中介机构存款，而是直接从事收益可能较低的投资； 政府管制的金融中介可能因地方性的、非正规的、地下的信贷市场的兴起而被削弱； 由于资金成本较低，银行借款人会产生对贷款的超额需求。为避免信贷扩张，必然实施行政性信贷配给。 金融自由化金融自由化是经济一体化和经济全球化的最高级形态。 从外延上看，金融自由化可分为对内自由化（利率市场化改革）和对外自由化（汇率改革，资本国际流动），前者指政府对国内金融机构和金融市场放松管制，以及推进国内利率的市场化；后者即金融国际化，表示一国放松对于外资金融机构的市场准入，并取消外汇管制。 改革的核心内容： 放松利率管制； 缩小指导性信贷计划实施范围； 减少金融机构审批限制，促进金融同业竞争； 发行直接融资工具，活跃证券市场； 放松对汇率和资本流动的限制。 正效应： 储蓄效应：储蓄增加，大量外资流入 投资效应：投资效率提高 就业效应：缓解失业状况收入 分配效应：有助于促进收入分配的平等 稳定效应：稳定经济及稳定货币政策 减少因政府干预带来的效率损失和贪污腐化 发展中国家金融自由化改革的经验和教训 要有稳定的宏观经济背景。 与价格改革或自由定价机制相配合。如果一国的价格是保护价格或管制价格，在这种价格信号扭曲的条件下实现金融自由化，资金流动就会被错误的价格信号所误导，出现新的资源配置机构失调。 改变直接干预的方式，以法律和规章的干预取代人为的干预。 事先预测相对价格变动对不同集团利益的影响，出于公平原则和政治均衡要求的考虑，适当采用经济补偿手段，减轻社会震荡。 普惠金融普惠金融：使用金融服务的个人和企业占到全部个人和企业的较高份额。 推动普惠金融发展的对策在以下基本方面达成了共识： 重视技术进步的作用。 创新产品设计与商业模式。 普及金融知识和提升金融能力。 强化消费者保护和市场监管。 政府的适当干预。 第二十八章 金融脆弱性与金融危机 1929-1933年大萧条 2008年次贷危机 2009年欧债危机 金融脆弱性狭义上的金融脆弱性：高负债经营的行业特点决定了金融业具有容易失败的特性。 广义上的金融脆弱性，泛指一切融资领域——包括金融机构融资和金融市场融资——中的风险积聚。 金融风险，是指潜在的损失可能性。金融脆弱是指风险积聚所形成的状态。 金融风险概念既用于微观领域，也用于宏观领域。金融脆弱性多用于对金融体系的讨论。 反映金融脆弱性的指标 短期债务与外汇储备比例失调 巨额经常账户逆差 预算赤字大 在资本流入的组成中，短期资本比例过高汇率定值过高 货币供给量迅速增加通货膨胀率在10个月内的平均水平高于历史平均水平8%以上 M2对官方储备比率连续12个月上升后急速下降 高利率 美国经济学家明斯基在《稳定不稳定的经济：一种金融不稳定视角》中提出“金融不稳定性假说”，认为私人信用创造机构特别是商业银行和其他相关的贷款人的内在特性使得它们不得不经历周期性危机和破产浪潮，银行部门的困境又被传递到经济体的各个组成部分，产生经济危机。 2016年 明斯基时刻 金融危机的含义及分类金融危机：全部或大部分金融指标——短期利率、资产价格、商业破产数和金融机构倒闭数——的急剧、短暂和超周期的变化。 次贷危机：与房地产市场有关，2001年美联储低利率，资金涌入房地产市场，但是2006年美联储加息，房价下降，违约情况增加，金融创新导致金融危机。（系统性风险），CDS投保做空，导致大量金融机构破产倒闭。 欧债危机：欧盟各国采用扩张的财政政策，政府赤字，政府违约 守住不发生系统性金融风险的底线 准确判断我国当前面临的金融风险（总体看，我国金融形势是好的，但当前和今后一个时期我国金融领域尚处在风险易发高发期） 介绍具体的金融风险（宝万之争 - 把保监会和银监会合并了） 如何防范系统性风险 金融危机的危害 使金融机构陷入经营困境 财政负担加重 降低货币政策效率。不稳定的银行体系打乱了货币政策工具与货币政策目标之间正常的联系规律 债务紧缩效应。在金融危机中许多银行的倒闭减小了金融中介活动和提供信贷的规模，使信贷紧上加紧，于是导致投资的过分缩减和总体经济水平的持续低迷 金融危机的诸多不利影响最终都打击经济增长 金融危机的防范与治理措施 建立危机预警系统。建立危机预警系统的主要工作是筛选并构建预警指标体系，在发生危机之前做好准备，保持警惕。 稳定金融市场。稳定金融市场的举措包括： 调用外汇储备调节外汇市场； 通过提高利率提高投机操作借用本币的成本，维持本币汇率； 财政介入，维持股市稳定； 保障储蓄与债券，避免存款人信心流失。 建立稳定机制，应对危机实施救助。 管理国际资本流动 课征短期资本流动税——托宾税 外汇流入流出限额 外汇投资证券限额 加强外债规模和结构管理 重组和改革金融部门 制定重组改革计划，确定执行机构。 处理不良资产，进行多渠道分离与处置。 帮助银行达成资本充足率，协助充实资本金。 引导外资参与国内金融修复。 提高金融机构的公司治理水平。 对有问题的金融机构进行合并与重组。 推进宏观及结构性改革 实施扩张性财政政策 实施扩张性货币政策 调整经济结构 第二十九章 金融监管金融监管的界说和理论 金融监管 金融监管是金融监督和金融管理的复合词。 狭义的金融监管指金融监管当局依据国家法律法规的授权对金融业实施监督、约束、管制，使之依法稳健运行的行为总称。 广义的金融监管除主管当局之外，还包括金融机构的内部控制与稽核、行业自律性组织的监督及社会中介组织的监督。 金融监管的基本原则 依法监管原则 合理、适度竞争原则 自我约束和外部强制相结合的原则 安全稳定与经济效率相结合的原则 监管内容、方式、手段等要适时调整原则 金融监管的理论依据 社会利益论：监管当局要维护社会利益 金融风险论：要控制金融风险 投资者利益保护论：要保护投资者利益 管制供求论：需求，那些想从监管中获得利益的人所需要的；供给，提供管制是为了得到对自身政绩更广泛的认可 公共选择论：管制寻租 金融监管体制 金融监管体制及其类型 金融监管体制是指金融监管的制度安排，主要包括金融监管当局对金融机构和金融市场施加影响的机制及监管的组织结构的安排。 单一监管体制：由一家金融监管机关对金融业实施高度集中监管的体制。单一体金融监管机关通常是各国的中央银行，也有另设独立监管机关的。 多头监管体制：根据从事金融业务的不同机构主体及其业务范围不同，有不同的监管机构分别实施监管的体制。（分权多头式和集权多头式） 我国（集权多头式）：一行三会 -&gt; 一委一行两会 一委：金融发展稳定委员会（用来应对金融机构混业经营的趋势） 一行：中国人民银行 两会：银保监会、证监会 银行国际监管《巴塞尔协议》：提高银行资本充足率（资本充足率 = 银行资本 / 风险加权资产，主要是信用风险，包括表内和表外两部分） 把银行资本划分为核心资本（股本和公开准备金，至少占全部资产的50%）与附属资本（未公开的准备金、资产重估准备金、普通准备金等） 资本充足率至少为8%，核心资本充足率至少为4% 《巴塞尔协议Ⅱ》：除了考虑信用风险，还考虑了市场风险和操作风险 三大支柱 最低资本要求：对风险加权资产的计算问题纳入了市场风险和操作风险，信用风险：将现有方法进行适当修改或内部评级法。对于市场风险更强调了利率风险。对于操作风险规定了基本指标法、标准法和高级计量法。 监管当局的监管 市场纪律：核心是信息披露 2008年次贷危机以后，《巴塞尔协议Ⅲ》：重视系统性风险 在原有微观审慎基础上重视宏观审慎，构建宏观审慎监管框架，加强对系统重要性金融机构的监管，防范大而不倒导致的道德风险和系统性风险 逆资本缓冲（防范于未然）：2.5%的储备资本和0~2.5%的逆周期资本要求 最低核心资本要求调整到4.5% 采用简单的表内外资产加总之和替代风险加权资产衡量资本充足率，防范模型风险 引入流动性监管标准，关注压力情形下的流动性管理 金融监管的国际协调 金融国际化给金融监管带来的挑战 金融监管国际协调面临的困难 金融监管国际协调的未来发展","link":"/2024/11/30/13-%E9%BB%84%E8%BE%BE%E9%87%91%E8%9E%8D%E5%AD%A6/"},{"title":"回归交互项的解读","text":"文章简单阐述了交互项的解读，以及其与机制、异质性、调节和分组回归的差异与联系 1 交互项的方程设定 —— 一个例子在机制或异质性分析中，交互项通常扮演着重要作用，即通过交互项的系数解读其经济含义。然而，我发现许多人对于如何解读交互项的数学统计含义都存有困难，更别说经济意义了，尤其是遇到双重差分的交互项（三重差分）时。更是一头雾水。因此，特撰此文以供讨论。 首先，我们以数字化转型 $DT$ 与企业融资约束 $FC$ 为例，构建如下基准模型：$$FC_{it} = \\alpha + \\beta DT_{it} + \\gamma’CONTROLS_{it} + \\delta_i + \\lambda_t + \\varepsilon_{it}$$如果不出意外的话，系数 $\\beta$ 应该显著为负，因为数字化转型能够降低企业所面临的融资约束问题，不妨假设系数 $\\beta = -0.1$。 接下来，我们假设信息不对称程度 $ASY$ 是数字化转型 $DT$ 降低企业融资约束 $FC$ 的机制变量（这里特别提一嘴，不再建议使用三步中介效应模型），那么在设定上，我们采用如下方程：$$FC_{it} = \\alpha + \\theta DT_{it} \\times ASY_{it} + \\beta DT_{it} + \\psi ASY_{it} + \\gamma’CONTROLS_{it} + \\delta_i + \\lambda_t + \\varepsilon_{it}$$在一般情况下，我们不能简单地将 $DT$ 与 $ASY$ 直接相乘（尽管不少文献是这么做的），更一般的，我们要将机制变量，也就是 $ASY$ 按照某种规则进行分组处理（例如全样本、行业-年份、城市-年份中位数等），从而生成一个 0-1 虚拟变量 $DASY$。$DASY = 0$ 代表信息不对称程度较低的那组，反之，则代表信息不对称较高的那组。上述模型即可改写为：$$FC_{it} = \\alpha + \\theta DT_{it} \\times DASY_{it} + \\phi DT_{it} + \\psi DASY_{it} + \\gamma’CONTROLS_{it} + \\delta_i + \\lambda_t + \\varepsilon_{it}$$那么，当信息不对称程度较高时，$DT$ 对 $FC$ 的边际效应为：$${\\frac{\\partial\\mathbb{E}[FC_{it} | DASY_{it} = 1]}{\\partial DT_{it}}} = \\theta + \\phi$$类似的，信息不对称程度较低时，有$${\\frac{\\partial\\mathbb{E}[FC_{it} | DASY_{it} = 0]}{\\partial DT_{it}}} = \\phi$$在本质上，交乘和分组时没区别的（当然，你想调节显著性的话还是有点区别的），比较上述两组边际效应可知，在信息不对称程度较高的一组，其边际效应比低组多 $\\theta$。 根据正常思路，数字化转型应当通过降低信息不对称程度，来缓解企业所面临的融资约束。因此，在信息不对称更高的一组，降低的效果应该更强，即 $\\theta$ 应当显著为负。只有这样，边际效应 $\\theta + \\phi$ 的绝对值才能大于边际效应 $\\phi$。 需要注意的是，如果数据是合理的，应该还要观察到系数（如果显著的话），$\\phi &lt; 0$，$\\psi &gt; 0$，因为数字化转型与融资约束的关系应当为负，信息不对称与融资约束关系应当为正。 2 机制的交互项解读 —— 更一般的规律通过上述分析，我们可以总结出更一般的规律，对于如下基准模型和交互模型：$$y_{it} = \\alpha + \\beta x_{it} + \\gamma’ controls_{it} + \\varepsilon_{it}$$ $${y_{it} = \\alpha + \\theta x_{it} \\times Dm_{it} + \\phi x_{it} + \\psi Dm_{it} + \\gamma’ controls_{it} + \\varepsilon_{it}}$$ 其中，$Dm$ 为机制变量所对应的 0-1 虚拟变量，$Dm = 1$ 为 $m$ 更高的那组。若 $m$ 为 $x$ 可影响的变量，且 $y$ 也受到 $m$ 影响，那么有如下关系（当然前提是符合理论逻辑，且系数显著）： $\\beta$ $\\theta$ 关系 - - $x$ 通过降低 $m$ 来降低 $y$ - + $x$ 通过增加 $m$ 来降低 $y$ + + $x$ 通过增加 $m$ 来增加 $y$ + - $x$ 通过降低 $m$ 来增加 $y$ 注意，这里提到 $m$ 必须是 $x$ 可影响的变量且可影响 $y$ 的变量才能用如上的方式进行解读。难道 $m$ 不能被 $x$ 影响就不能作为机制了吗？显然不是（但大多数情况是的）。例如“寻租效应”可以通过“是否国企（$SOE$）”和“是否政治关联（$PR$）”来生成交互变量，如果观察到国企或具有政治关联的企业有更强的效应，那么即可验证“寻租效应”是研究的一条机制（当然前提还是符合理论逻辑）。 3 机制和异质性的区别 —— 越来越模糊？现在一些文章不会刻意强调进行的交乘回归或者分组回归到底是机制还是异质性，只因二者的模型和方法过于相似，曾经我还见到过声称“交乘做机制，分组做异质性”、“机制和异质性只是分组方法不同”等评论，但事实上，所研究的到底是机制还是分组，更重要的是变量的选取和理论逻辑的合理性。 例如，在数字化转型和融资约束的研究中，学者们通常会探究企业规模、东西部地区、产权性质等对异质性作用。但是会有人把这些变量当作机制吗？显然不会，因为这类变量对于研究为什么数字化转型会降低融资约束只能起到一个拓展性的作用，无法解释其中的影响渠道。那么现在论文中关于机制、异质性、调节、分组、交乘等等究竟是什么关系呢？个人之见如下： 机制：探究“为什么 $x$ 会影响 $y$”这一问题，可以采用交乘、分组或直接对 $m$ 回归的方法进行检验（还有不建议的中介效应模型） 异质性：拓展 $x$ 对 $y$ 经济效应的研究，但无法解释为什么 $x$ 会影响 $y$，可以采用交乘和分组方法进行检验 调节：交乘和分组方法的统称，所谓调节效应就是类似于前文中提到的，两个边际效应的差值 $\\theta$ 交乘：通过设定类似于模型 ${y_{it} = \\alpha + \\theta x_{it} \\times Dm_{it} + \\phi x_{it} + \\psi Dm_{it} + \\gamma’ controls_{it} + \\varepsilon_{it}}$ 的方法对机制或异质性进行分组，观察交互项系数与基准回归系数得出结论 分组：通过一定的规则区分样本，然后分别对基准模型进行回归，比较两组系数差异得出结论 4 交乘的交乘 —— 还是建议分组吧如果想要通过交乘方法检验交互基准模型的机制，以数字化转型为例，我们探究规模交互下，信息不对称的机制作用$$\\begin{aligned}FC_{it} &amp;= \\alpha + \\sigma DT_{it} \\times DSMALL_{it} + \\phi_1 DT_{it} + \\phi_2 DSMALL_{it} + \\gamma’CONTROLS_{it} + \\delta_i + \\lambda_t + \\varepsilon_{it}\\end{aligned}$$ $$\\begin{aligned}FC_{it} &amp;= \\alpha + \\theta DT_{it} \\times DSMALL_{it} \\times DASY_{it}\\&amp;+ \\beta_1 DT_{it} \\times DSMALL_{it} + \\beta_2 DT_{it} \\times DASY_{it} + \\beta_3 DASY_{it} \\times DSMALL_{it}\\&amp;+ \\psi_1 DT_{it} + \\psi_2 DSMALL_{it} + \\psi_3 DASY_{it} + \\gamma’CONTROLS_{it} + \\delta_i + \\lambda_t + \\varepsilon_{it}\\end{aligned}$$ 其中，$DSMALL = 1$ 代表企业规模低于中位数的企业。 是不是已经开始眼花缭乱了？有人会质疑，那些单项有必要放吗？只放第一项 $DT_{it} \\times DSMALL_{it} \\times DASY_{it}$ 难道不可以？很遗憾，从计量的角度来看，这样操作会导致严重的遗漏变量问题，因为模型没有把 $DT$、$DASY$ 等作用从交互项中剥离出来，所估计的系数必然有偏。 那么如何解读呢？事实上还是关注交互项系数就好。首先看基准回归，数字化转型对于中小企业的作用应当更大，所以系数 $\\sigma$ 应该显著为负，系数 $\\phi_1$ 也显著为负。 来到交互模型这里，如果想要验证数字化转型通过降低中小企业的信息不对称程度来实现缓解融资约束，那么交互项 $DT_{it} \\times DSMALL_{it} \\times DASY_{it}$ 的系数 $\\theta$ 应该显著为负，因为在信息不对称更高的一组（$DASY = 1$），这种效应将会更强。 但，言归正传，模型设定上太过复杂，这种情况下可能分组会更好理解一些。","link":"/2024/07/06/10-%E5%9B%9E%E5%BD%92%E4%BA%A4%E4%BA%92%E9%A1%B9%E7%9A%84%E8%A7%A3%E8%AF%BB/"},{"title":"Stata 外部命令安装","text":"常用的 Stata 外部命令 1 外部命令1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950* reghdfe 版本管理net install reghdfe, from(&quot;.\\reghdfe-6.12.4\\reghdfe&quot;) replacenet install ivreghdfe, from(&quot;.\\ivreghdfe-1.1.3&quot;) replacenet install ftools, from(&quot;.\\ftools-2.49.1&quot;)ssc install ivreg2, replacessc install corr2docx, replacessc install reg2docx, replacessc install psmatch2, replacessc install winsor2, replacessc install asreg, replacessc install ardl, replacessc install bdiff, replacessc install coefplot, replacessc install ebalance, replacessc install egenmore, replacessc install fs, replacessc install inlist2, replacessc install konfound, replacessc install mipolate, replacessc install moss, replacessc install overid, replacessc install openall, replacessc install psacalc, replace // 支持 reghdfe 的 psacalc2 去 Github 下载ssc install runby, replacessc install sicff, replacessc install ttable3, replacessc install weakivtest, replacessc install xtscc, replacessc install xtmipolateu, replacessc instal require, replacessc install summarizeby, replacessc install ranktest, replacessc install dpplot, replacessc install ivreg2h, replace // lewbel ivssc install factortest, replacessc install center, replacessc install bcuse, replacessc install indeplist, replacessc install matsort, replacessc install bacondecomp, replacessc install csdid, replacessc install drdid, replacessc install fuzzydid, replacessc install chowtest, replacessc install ereplace, replacessc install keeporder, replacessc install gtools, replacenet install st0085_2.pkg, replace // est 全家桶net install st0373.pkg, replace // 门槛回归，网上还有能加固定效应的资源，可以搜搜看 2 profile.do123456789101112131415161718set type double // 设定 generate 命令产生的新变量为双精度类型set memory 100m // 为 Stata 分配 100m 内存set matsize 2000 // 设定矩阵的维度为 2000x2000set scrollbufsize 500000 // 结果窗口中显示的行数上限set more off, perma // 关闭分页提示符// set timeout1 120sysdir set PLUS &quot;`c(sysdir_stata)'ado\\plus&quot; // 外部命令的存放位置* sysdir set PLUS &quot;`c(sysdir_stata)'ado\\plus_ok&quot; // 外部命令的存放位置sysdir set OLDPLACE &quot;`c(sysdir_stata)'ado\\personal&quot; // 自行编写的stata程序sysdir set PERSONAL &quot;`c(sysdir_stata)'ado\\personal&quot; // 个人文件夹位置// 增加搜索路径* adopath + &quot;`c(sysdir_stata)'ado\\personal\\r_regressions&quot;// 更改工作目录cd &quot;D:\\code\\Stata&quot;","link":"/2024/06/20/9-Stata%20%E5%A4%96%E9%83%A8%E5%91%BD%E4%BB%A4%E5%AE%89%E8%A3%85/"},{"title":"Lewbel 工具变量法","text":"该命令将 lewbel 检验和 ivreghdfe、reghdfe 结合起来，并补充异方差检验 1 命令格式1lewbel varlist [if] [in], Absorb(string) [VCE(string) CLuster(string) Z(string) BY(string) first keep opt(string)] absorb()：和reghdfe一样，放固定效应即可 vce() &amp; cluster()：聚类稳健标准误，二者选一个即可，如果是低版本的ivreghdfe建议采用cluster，格式参考reghdfe和ivreghdfe z()：指定使用的外生变量，可以是控制变量的子集，也可以是新的变量。没有指定的时候默认采用所有控制变量 by(): 指定计算中心化时的均值分组，默认采用全样本均值（正如 ivreg2h 所做的） first：报告第一阶段回归结果 keep：保留生成的工具变量，以 _g 结尾 opt()：其他自定义的ivreghdfe参数，估计也用不上 2 原理 估计方程 $$Y_{it} = \\alpha_0 + \\alpha_1 X + \\eta’Controls_{i, t} + \\delta_i + \\lambda_t + \\varepsilon_{i, t} \\tag{1}$$ 计算残差 $$X_{it} = \\beta_0 + \\gamma’Controls_{i, t} + \\delta_i + \\lambda_t + \\mu_{i, t} \\tag{2}$$ 从控制变量（包括固定效应中）选取一部分变量作为外生变量 $Z$，这里选取所有的 $Controls$ 作为外生变量 $Z$​ 将向量 $Z$ 中所有变量均减去自身的全样本均值，然后乘以方程（2）的残差估计值，即：$Z_{IV} = (Z - \\overline{Z}) \\times \\hat{\\mu}_{it}$ 2SLS 把 $Z_{IV}$ 和 $Controls$​ 作为工具变量对方程（1）进行二阶段回归，即 第一阶段$$X_{it} = \\theta_0 + \\theta_1 Z_{IV} + \\Phi’Controls_{i, t} + \\delta_i + \\lambda_t + \\sigma_{i, t} \\tag{3}$$根据（3）的拟合值，估计第二阶段$$Y_{it} = \\psi_0 + \\psi_1 \\hat{X} + \\Omega’Controls_{i, t} + \\delta_i + \\lambda_t + \\epsilon_{i, t} \\tag{4}$$ 3 例子1234567891011121314151617181920212223242526272829303132use &quot;lewbel test.dta&quot;, clearxtset id yeargen Ind_year = string(Industry) + &quot; $ &quot; + string(year)* Use lewbel commandlewbel y x1 x2-x9 , a(Country Ind_year) cl(Ind_year) keep firstest store m3* First stagereghdfe x1 x2_g-x9_g x2-x9, a(Country Ind_year) cl(Ind_year)est store m1* Predictqui predict x1_p* Second stagereghdfe y x1_p x2-x9, a(Country Ind_year) cl(Ind_year)est store m2reg2docx m1 m2 m3 using &quot;lewbel.docx&quot;, replace /// b(%20.4f) t(%20.4f) /// scalars(N(%20.0fc) r2_a(%20.4f) HetLM(%20.4f) HetLMp(%20.4f) /// Kleibergen_Paap_rk_LM(%20.4f) Kleibergen_Paap_rk_LM_p(%20.4f) /// Cragg_Donald_Wald_F(%20.4f) Kleibergen_Paap_rk_Wald_F(%20.4f) /// Hansen_J(%20.4f) Hansen_J_p(%20.4f)) /// order(x1 x1_p) /// addfe(&quot;Country=YES&quot; &quot;Industry*Year=YES&quot;) /// mtitles() /// font(&quot;Times New Roman&quot;, 6.5) /// margin(top, 3.17cm) margin(bottom, 3.17cm) Stata 输出结果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269. lewbel y x1 $controls , a(Country Ind_year) cl(Ind_year) keep first*=============================================================================** Part 1 Heteroskedasticity test **=============================================================================*Breusch–Pagan test for heteroskedasticityH0: Constant variance Chi2(2651) = 4792.7716 Prob &gt; chi2 = 0.0000*=============================================================================** Part 2 2SLS regression **=============================================================================*(MWFE estimator converged in 8 iterations)First-stage regressions-----------------------First-stage regression of x1:Statistics robust to heteroskedasticity and clustering on Ind_yearNumber of obs = 20537Number of clusters (Ind_year) = 2629------------------------------------------------------------------------------ | Robust x1 | Coefficient std. err. t P&gt;|t| [95% conf. interval]-------------+---------------------------------------------------------------- x2_g | .3403562 .030574 11.13 0.000 .2804287 .4002837 x3_g | .0209829 .0210201 1.00 0.318 -.0202182 .0621839 x4_g | -.1824731 .0274428 -6.65 0.000 -.2362632 -.128683 x5_g | -.0202362 .0187698 -1.08 0.281 -.0570265 .0165541 x6_g | .0300076 .0200092 1.50 0.134 -.0092121 .0692273 x7_g | .0264974 .0227246 1.17 0.244 -.0180446 .0710393 x8_g | .0312092 .0336754 0.93 0.354 -.0347972 .0972156 x9_g | .1917831 .0199648 9.61 0.000 .1526505 .2309157 x2 | .5211517 .0056266 92.62 0.000 .5101231 .5321804 x3 | .0167608 .0049286 3.40 0.001 .0071003 .0264213 x4 | .0049114 .0058779 0.84 0.403 -.0066098 .0164326 x5 | .0670301 .0052558 12.75 0.000 .0567283 .0773319 x6 | -.0271468 .0044682 -6.08 0.000 -.0359047 -.0183888 x7 | .0478391 .0057346 8.34 0.000 .0365988 .0590794 x8 | -.0415018 .0050295 -8.25 0.000 -.0513599 -.0316436 x9 | -.0220721 .0042422 -5.20 0.000 -.0303873 -.013757------------------------------------------------------------------------------F test of excluded instruments: F( 8, 2628) = 78.98 Prob &gt; F = 0.0000Sanderson-Windmeijer multivariate F test of excluded instruments: F( 8, 2628) = 78.98 Prob &gt; F = 0.0000Summary results for first-stage regressions------------------------------------------- (Underid) (Weak id)Variable | F( 8, 2628) P-val | SW Chi-sq( 8) P-val | SW F( 8, 2628)x1 | 78.98 0.0000 | 633.01 0.0000 | 78.98NB: first-stage test statistics cluster-robustStock-Yogo weak ID F test critical values for single endogenous regressor: 5% maximal IV relative bias 20.25 10% maximal IV relative bias 11.39 20% maximal IV relative bias 6.69 30% maximal IV relative bias 4.99 10% maximal IV size 33.84 15% maximal IV size 18.54 20% maximal IV size 13.24 25% maximal IV size 10.50Source: Stock-Yogo (2005). Reproduced by permission.NB: Critical values are for i.i.d. errors only.Underidentification testHo: matrix of reduced form coefficients has rank=K1-1 (underidentified)Ha: matrix has rank=K1 (identified)Kleibergen-Paap rk LM statistic Chi-sq(8)=111.38 P-val=0.0000Weak identification testHo: equation is weakly identifiedCragg-Donald Wald F statistic 455.55Kleibergen-Paap Wald rk F statistic 78.98Stock-Yogo weak ID test critical values for K1=1 and L1=8: 5% maximal IV relative bias 20.25 10% maximal IV relative bias 11.39 20% maximal IV relative bias 6.69 30% maximal IV relative bias 4.99 10% maximal IV size 33.84 15% maximal IV size 18.54 20% maximal IV size 13.24 25% maximal IV size 10.50Source: Stock-Yogo (2005). Reproduced by permission.NB: Critical values are for Cragg-Donald F statistic and i.i.d. errors.Weak-instrument-robust inferenceTests of joint significance of endogenous regressors B1 in main equationHo: B1=0 and orthogonality conditions are validAnderson-Rubin Wald test F(8,2628)= 4.74 P-val=0.0000Anderson-Rubin Wald test Chi-sq(8)= 38.02 P-val=0.0000Stock-Wright LM S statistic Chi-sq(8)= 38.09 P-val=0.0000NB: Underidentification, weak identification and weak-identification-robust test statistics cluster-robustNumber of clusters N_clust = 2629Number of observations N = 20537Number of regressors K = 9Number of endogenous regressors K1 = 1Number of instruments L = 16Number of excluded instruments L1 = 8IV (2SLS) estimation--------------------Estimates efficient for homoskedasticity onlyStatistics robust to heteroskedasticity and clustering on Ind_yearNumber of clusters (Ind_year) = 2629 Number of obs = 20537 F( 9, 2628) = 422.69 Prob &gt; F = 0.0000Total (centered) SS = 14633.8475 Centered R2 = 0.2665Total (uncentered) SS = 14633.8475 Uncentered R2 = 0.2665Residual SS = 10733.40994 Root MSE = .7233------------------------------------------------------------------------------ | Robust y | Coefficient std. err. t P&gt;|t| [95% conf. interval]-------------+---------------------------------------------------------------- x1 | -.0958878 .0328708 -2.92 0.004 -.1603431 -.0314325 x2 | .3531729 .0213118 16.57 0.000 .3113833 .3949625 x3 | -.0767336 .007376 -10.40 0.000 -.0911971 -.0622702 x4 | -.0302413 .0083046 -3.64 0.000 -.0465255 -.0139571 x5 | .0566474 .0073346 7.72 0.000 .0422652 .0710295 x6 | -.134026 .0080818 -16.58 0.000 -.1498734 -.1181787 x7 | .0218564 .0087345 2.50 0.012 .0047292 .0389836 x8 | .042576 .0087935 4.84 0.000 .0253332 .0598188 x9 | -.3142137 .0076184 -41.24 0.000 -.3291524 -.299275------------------------------------------------------------------------------Underidentification test (Kleibergen-Paap rk LM statistic): 111.379 Chi-sq(8) P-val = 0.0000------------------------------------------------------------------------------Weak identification test (Cragg-Donald Wald F statistic): 455.554 (Kleibergen-Paap rk Wald F statistic): 78.984Stock-Yogo weak ID test critical values: 5% maximal IV relative bias 20.25 10% maximal IV relative bias 11.39 20% maximal IV relative bias 6.69 30% maximal IV relative bias 4.99 10% maximal IV size 33.84 15% maximal IV size 18.54 20% maximal IV size 13.24 25% maximal IV size 10.50Source: Stock-Yogo (2005). Reproduced by permission.NB: Critical values are for Cragg-Donald F statistic and i.i.d. errors.------------------------------------------------------------------------------Hansen J statistic (overidentification test of all instruments): 30.013 Chi-sq(7) P-val = 0.0001------------------------------------------------------------------------------Instrumented: x1Included instruments: x2 x3 x4 x5 x6 x7 x8 x9Excluded instruments: x2_g x3_g x4_g x5_g x6_g x7_g x8_g x9_gPartialled-out: _cons nb: total SS, model F and R2s are after partialling-out; any small-sample adjustments include partialled-out variables in regressor count K------------------------------------------------------------------------------Absorbed degrees of freedom:-----------------------------------------------------+ Absorbed FE | Categories - Redundant = Num. Coefs |-------------+---------------------------------------| Country | 15 1 14 | Ind_year | 2629 2629 0 *|-----------------------------------------------------+* = FE nested within cluster; treated as redundant for DoF computation. est store m3. . * First stage. reghdfe x1 x2_g-x9_g x2-x9, a(Country Ind_year) cl(Ind_year)(MWFE estimator converged in 8 iterations)HDFE Linear regression Number of obs = 20,537Absorbing 2 HDFE groups F( 16, 2628) = 909.28Statistics robust to heteroskedasticity Prob &gt; F = 0.0000 R-squared = 0.8245 Adj R-squared = 0.7984 Within R-sq. = 0.5411Number of clusters (Ind_year) = 2,629 Root MSE = 0.4494 (Std. err. adjusted for 2,629 clusters in Ind_year)------------------------------------------------------------------------------ | Robust x1 | Coefficient std. err. t P&gt;|t| [95% conf. interval]-------------+---------------------------------------------------------------- x2_g | .3403562 .0305747 11.13 0.000 .2804032 .4003092 x3_g | .0209829 .0210206 1.00 0.318 -.0202358 .0622015 x4_g | -.1824731 .0274435 -6.65 0.000 -.2362861 -.12866 x5_g | -.0202362 .0187703 -1.08 0.281 -.0570422 .0165698 x6_g | .0300076 .0200097 1.50 0.134 -.0092288 .069244 x7_g | .0264974 .0227251 1.17 0.244 -.0180636 .0710583 x8_g | .0312092 .0336762 0.93 0.354 -.0348254 .0972437 x9_g | .1917831 .0199653 9.61 0.000 .1526338 .2309324 x2 | .5211517 .0056268 92.62 0.000 .5101184 .5321851 x3 | .0167608 .0049288 3.40 0.001 .0070962 .0264255 x4 | .0049114 .0058781 0.84 0.403 -.0066147 .0164375 x5 | .0670301 .0052559 12.75 0.000 .056724 .0773363 x6 | -.0271468 .0044683 -6.08 0.000 -.0359084 -.0183851 x7 | .0478391 .0057348 8.34 0.000 .036594 .0590842 x8 | -.0415018 .0050296 -8.25 0.000 -.0513641 -.0316394 x9 | -.0220721 .0042423 -5.20 0.000 -.0303908 -.0137535 _cons | -3.630724 .0837772 -43.34 0.000 -3.795 -3.466448------------------------------------------------------------------------------Absorbed degrees of freedom:-----------------------------------------------------+ Absorbed FE | Categories - Redundant = Num. Coefs |-------------+---------------------------------------| Country | 15 1 14 | Ind_year | 2629 2629 0 *|-----------------------------------------------------+* = FE nested within cluster; treated as redundant for DoF computation. est store m1. . * Predict. qui predict x1_p. . * Second stage. reghdfe y x1_p x2-x9, a(Country Ind_year) cl(Ind_year)(MWFE estimator converged in 8 iterations)HDFE Linear regression Number of obs = 20,537Absorbing 2 HDFE groups F( 9, 2628) = 423.63Statistics robust to heteroskedasticity Prob &gt; F = 0.0000 R-squared = 0.4743 Adj R-squared = 0.3964 Within R-sq. = 0.2652Number of clusters (Ind_year) = 2,629 Root MSE = 0.7754 (Std. err. adjusted for 2,629 clusters in Ind_year)------------------------------------------------------------------------------ | Robust y | Coefficient std. err. t P&gt;|t| [95% conf. interval]-------------+---------------------------------------------------------------- x1_p | -.0958878 .0339678 -2.82 0.005 -.1624942 -.0292814 x2 | .3531729 .0214141 16.49 0.000 .3111827 .3951632 x3 | -.0767336 .0073749 -10.40 0.000 -.0911947 -.0622725 x4 | -.0302413 .0082708 -3.66 0.000 -.0464593 -.0140233 x5 | .0566474 .007391 7.66 0.000 .0421546 .0711401 x6 | -.134026 .0080965 -16.55 0.000 -.1499023 -.1181498 x7 | .0218564 .0088265 2.48 0.013 .0045489 .0391639 x8 | .042576 .0087784 4.85 0.000 .0253627 .0597892 x9 | -.3142137 .0076214 -41.23 0.000 -.3291582 -.2992692 _cons | -3.162962 .208469 -15.17 0.000 -3.571741 -2.754182------------------------------------------------------------------------------Absorbed degrees of freedom:-----------------------------------------------------+ Absorbed FE | Categories - Redundant = Num. Coefs |-------------+---------------------------------------| Country | 15 1 14 | Ind_year | 2629 2629 0 *|-----------------------------------------------------+* = FE nested within cluster; treated as redundant for DoF computation 图表导出结果： 4 命令 &amp; 数据下载GitHub 仓库：https://github.com/codefoxs/Stata-personal 12345* Installnet install command, from(&quot;https://raw.githubusercontent.com/codefoxs/Stata-personal/main/lewbel/&quot;) replace* Versionwhich lewbel 5 参考文献 Lewbel, A. (2012). Using Heteroscedasticity to Identify and Estimate Mismeasured and Endogenous Regressor Models. Journal of Business & Economic Statistics, 30(1), 67–80. https://doi.org/10.1080/07350015.2012.643126","link":"/2024/05/17/3-Lewbel-%E5%B7%A5%E5%85%B7%E5%8F%98%E9%87%8F%E6%B3%95/"},{"title":"堆叠双重差分模型","text":"堆叠双重差分模型方法 1 堆叠DID（stacked DID）和多期DID（staggered DID）的区别1.1 Difference in data Setting Sample windows: 2001 - 2005 Adoption year stkcd Group type 1999 1 Always treated 2002 2 Early treated 2004 3 Late treated . 4 Never treated Staggered DID panel data (N = 4 $\\times$ 5 = 20) stkcd year y DID Treat Adoption year 1 2001 55 1 1 1999 1 2002 64 1 1 1999 1 2003 21 1 1 1999 1 2004 45 1 1 1999 1 2005 67 1 1 1999 2 2001 82 0 1 2002 2 2002 63 1 1 2002 2 2003 78 1 1 2002 2 2004 99 1 1 2002 2 2005 51 1 1 2002 3 2001 54 0 1 2004 3 2002 36 0 1 2004 3 2003 41 0 1 2004 3 2004 65 1 1 2004 3 2005 94 1 1 2004 4 2001 76 0 0 . 4 2002 37 0 0 . 4 2003 11 0 0 . 4 2004 76 0 0 . 4 2005 44 0 0 . Stacked DID panel data (N = 3 $\\times$ 10 = 30) stkcd year y DID Treat Adoption year in cohort Cohort 1 2001 55 1 1 1999 1 1 2002 64 1 1 1999 1 1 2003 21 1 1 1999 1 1 2004 45 1 1 1999 1 1 2005 67 1 1 1999 1 4 2001 76 0 0 . 1 4 2002 37 0 0 . 1 4 2003 11 0 0 . 1 4 2004 76 0 0 . 1 4 2005 44 0 0 . 1 2 2001 82 0 1 2002 2 2 2002 63 1 1 2002 2 2 2003 78 1 1 2002 2 2 2004 99 1 1 2002 2 2 2005 51 1 1 2002 2 4 2001 76 0 0 . 2 4 2002 37 0 0 . 2 4 2003 11 0 0 . 2 4 2004 76 0 0 . 2 4 2005 44 0 0 . 2 3 2001 54 0 1 2004 3 3 2002 36 0 1 2004 3 3 2003 41 0 1 2004 3 3 2004 65 1 1 2004 3 3 2005 94 1 1 2004 3 4 2001 76 0 0 . 3 4 2002 37 0 0 . 3 4 2003 11 0 0 . 3 4 2004 76 0 0 . 3 4 2005 44 0 0 . 3 1.2 Difference in specification Staggered DID specification $$y_{it} = \\alpha + \\beta DID_{it} + \\eta’ Controls_{it} + \\delta_{i} + \\lambda_{t} + \\varepsilon_{it}$$ where $y_{it}$ is the outcome variable $DID_{it}$ is the event dummy variable $Controls_{it}$ is a vector contains a series of variables $\\delta_i$ and $\\lambda_t$ are firm and year fixed effect, respectively Stacked DID Reduced form $$y_{ict} = \\alpha + \\beta DID_{ict} + \\eta’ Controls_{ict} + \\delta_{ic} + \\lambda_{tc} + \\varepsilon_{ict}$$ where $c$ is the cohort of firm $i$ $\\delta_{ic}$ and $\\lambda_{tc}$ are firm-cohort and year-cohort interacted fixed effect, respectively Event study form $$y_{ict} = \\alpha + \\sum\\limits_{\\begin{array}{*{20}{c}}{- 3 \\leqslant k \\leqslant 3} \\{k \\ne - 1}\\end{array}}\\beta_k Treat_{ic} \\times I( t - A_c = k ) + \\eta’ Controls_{ict} + \\delta_{ic} + \\lambda_{tc} + \\varepsilon_{ict}$$ where $A_c$ is the adoption year of cohort $c$ $I()$ is an indicator function, equaling 1 when the inner equation holds or more specifically$$y_{ict} = \\alpha + Before3_{ict} + Before2_{ict} + Currenct_{ict} + After1_{ict} + After2_{ict} + After3_{ict} + \\eta’ Controls_{ict} + \\delta_{ic} + \\lambda_{tc} + \\varepsilon_{ict}$$ 2 偏误的来源 Two assumption for common trend Time-varying confounders must affect outcomes in both groups in the same way. -&gt; Time fixed effects Group-varying confounders must be time-invariant. -&gt; Group fixed effects Goodman-Bacon, A. (2021). Difference-in-differences with variation in treatment timing. Journal of Econometrics, 225(2): 254-277. Because the early group (bad control) is treated as a control group See more details in Staggered Adoption Designs and Stacked DID and Event Studies (Coady Wing, 2021) 3 Stata code3.1 Staggered DID code 12345cd &quot;D:\\code\\Stata\\stackeddid&quot;use &quot;demo.dta&quot;, clear* Staggered didreghdfe y did, a(stkcd year) vce(cl stkcd) output 1234567891011121314151617181920212223242526272829. reghdfe y did, a(stkcd year) vce(cl stkcd)(MWFE estimator converged in 2 iterations)HDFE Linear regression Number of obs = 20Absorbing 2 HDFE groups F( 1, 3) = 17.15Statistics robust to heteroskedasticity Prob &gt; F = 0.0256 R-squared = 0.5608 Adj R-squared = 0.1656 Within R-sq. = 0.0988Number of clusters (stkcd) = 4 Root MSE = 20.9805 (Std. err. adjusted for 4 clusters in stkcd)------------------------------------------------------------------------------ | Robust y | Coefficient std. err. t P&gt;|t| [95% conf. interval]-------------+---------------------------------------------------------------- did | 19.26923 4.65359 4.14 0.026 4.459429 34.07903 _cons | 47.35192 2.559475 18.50 0.000 39.20653 55.49731------------------------------------------------------------------------------Absorbed degrees of freedom:-----------------------------------------------------+ Absorbed FE | Categories - Redundant = Num. Coefs |-------------+---------------------------------------| stkcd | 4 4 0 *| year | 5 0 5 |-----------------------------------------------------+* = FE nested within cluster; treated as redundant for DoF computation 3.2 Stacked DID code 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667cd &quot;D:\\code\\Stata\\stackeddid&quot;use &quot;demo.dta&quot;, clear* Stacked did// adoption year = 1999drop if adoptionyear == 2002drop if adoptionyear == 2004gen cohort = 1save &quot;cohort1.dta&quot;, replace// adoption year = 2002use &quot;demo.dta&quot;, cleardrop if adoptionyear == 1999drop if adoptionyear == 2004gen cohort = 2save &quot;cohort2.dta&quot;, replace// adoption year = 2004use &quot;demo.dta&quot;, cleardrop if adoptionyear == 1999drop if adoptionyear == 2002gen cohort = 3save &quot;cohort3.dta&quot;, replaceappend using &quot;cohort1.dta&quot;append using &quot;cohort2.dta&quot;sort cohort stkcd yearsave &quot;stackedmain.dta&quot;, replacereghdfe y did, a(stkcd#cohort year#cohort) vce(cl stkcd)// event study formforvalue i = 3(-1)2{ gen Before`i'_ = cond(year - adoptionyear &lt;= -`i' &amp; adoptionyear != ., 1, 0)}forvalue i = 3(-1)1{ gen Before`i' = cond(year - adoptionyear == -`i', 1, 0)}forvalue i = 0(1)3{ gen After`i' = cond(year - adoptionyear == `i', 1, 0)}forvalue i = 2(1)3{ gen After`i'_ = cond(year - adoptionyear &gt;= `i' &amp; adoptionyear != ., 1, 0)}reghdfe y Before3 Before2 After0 After1 After2 After3, a(stkcd#cohort year#cohort) vce(cl stkcd)est store m1coefplot m1, keep(Before3 Before2 After0 After1 After2 After3) /// levels(90) /// vertical yline(0) xline(3, lp(dash)) /// addplot(line @b @at) ciopts(lpattern(dash) /// recast(rcap) msize(medium)) /// msymbol(circle_hollow) /// scheme(s1mono) result 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364. reghdfe y did, a(stkcd#cohort year#cohort) vce(cl stkcd)(MWFE estimator converged in 2 iterations)HDFE Linear regression Number of obs = 30Absorbing 2 HDFE groups F( 1, 3) = 89.20Statistics robust to heteroskedasticity Prob &gt; F = 0.0025 R-squared = 0.7619 Adj R-squared = 0.1367 Within R-sq. = 0.0929Number of clusters (stkcd) = 4 Root MSE = 22.3113 (Std. err. adjusted for 4 clusters in stkcd)------------------------------------------------------------------------------ | Robust y | Coefficient std. err. t P&gt;|t| [95% conf. interval]-------------+---------------------------------------------------------------- did | 20.2 2.138754 9.44 0.003 13.39353 27.00647 _cons | 47.49333 .7842096 60.56 0.000 44.99763 49.98904------------------------------------------------------------------------------Absorbed degrees of freedom:--------------------------------------------------------+ Absorbed FE | Categories - Redundant = Num. Coefs |----------------+---------------------------------------| stkcd#cohort | 6 6 0 *| year#cohort | 15 0 15 |--------------------------------------------------------+* = FE nested within cluster; treated as redundant for DoF computation. reghdfe y Before3 Before2 After0 After1 After2 After3, a(stkcd#cohort year#cohort) vce(cl stkcd)(MWFE estimator converged in 2 iterations)warning: missing F statistic; dropped variables due to collinearity or too few clustersHDFE Linear regression Number of obs = 30Absorbing 2 HDFE groups F( 6, 3) = .Statistics robust to heteroskedasticity Prob &gt; F = . R-squared = 0.8914 Adj R-squared = -0.0501 Within R-sq. = 0.5863Number of clusters (stkcd) = 4 Root MSE = 24.6071 (Std. err. adjusted for 4 clusters in stkcd)------------------------------------------------------------------------------ | Robust y | Coefficient std. err. t P&gt;|t| [95% conf. interval]-------------+---------------------------------------------------------------- Before3 | -33.27778 10.94557 -3.04 0.056 -68.11146 1.555902 Before2 | -12.27778 10.94557 -1.12 0.344 -47.11146 22.5559 After0 | -7.916667 20.0721 -0.39 0.720 -71.79504 55.96171 After1 | 43.08333 12.77056 3.37 0.043 2.441714 83.72495 After2 | -9.972222 11.97396 -0.83 0.466 -48.0787 28.13425 After3 | 6.027778 13.48936 0.45 0.685 -36.90138 48.95693 _cons | 54.33704 3.490034 15.57 0.001 43.23019 65.44388------------------------------------------------------------------------------Absorbed degrees of freedom:--------------------------------------------------------+ Absorbed FE | Categories - Redundant = Num. Coefs |----------------+---------------------------------------| stkcd#cohort | 6 6 0 *| year#cohort | 15 0 15 |--------------------------------------------------------+* = FE nested within cluster; treated as redundant for DoF computation 4 参考文献 Chen, Z., Cao, Y., Feng, Z., Lu, M., & Shan, Y. (2023). Broadband infrastructure and stock price crash risk: Evidence from a quasi-natural experiment. Finance Research Letters, 58, 104026. Q2. https://doi.org/10.1016/j.frl.2023.104026","link":"/2024/04/11/1-%E5%A0%86%E5%8F%A0%E5%8F%8C%E9%87%8D%E5%B7%AE%E5%88%86%E6%A8%A1%E5%9E%8B/"},{"title":"各种分组回归方法","text":"本文总结了各种常用和不常用的分组回归命令 12345678* 需要安装 runbyssc install runby// 后面发现好像可以不用 runby，但是我的 Stata 需要 ssc install egenmoressc install egenmore* 测试数据集webuse nlsworkxtset idcode year 1 全样本中位数分组12345egen med = median(age)gen gvar = (age &gt;= med) if !mi(age)reghdfe ln_wage tenure ttl_exp, a(idcode year) vce(cl idcode), if gvar == 0reghdfe ln_wage tenure ttl_exp, a(idcode year) vce(cl idcode), if gvar == 1 2 按照同年份中位数分组12345bys year: egen med = median(age)gen gvar = (age &gt;= med) if !mi(age)reghdfe ln_wage tenure ttl_exp, a(idcode year) vce(cl idcode), if gvar == 0reghdfe ln_wage tenure ttl_exp, a(idcode year) vce(cl idcode), if gvar == 1 3 按照同行业同年份中位数分组12345bys ind_code year: egen med = median(age)gen gvar = (age &gt;= med) if !mi(age)reghdfe ln_wage tenure ttl_exp, a(idcode year) vce(cl idcode), if gvar == 0reghdfe ln_wage tenure ttl_exp, a(idcode year) vce(cl idcode), if gvar == 1 4 按照某一指定年份中位数分组1234567891011gen dc = agegen temp = dc if year == 2014bys code: egen gvar_in_year = min(temp)egen gvar_in_year_median = median(gvar_in_year)gen gvar = (gvar_in_year &gt; gvar_in_year_median) if !mi(gvar_in_year)* 更建议先在原始文件里先处理成指定年份再 merge，然后直接用全样本中位数即可* 不建议先在原始文件里分组再 merge，可能会导致两组样本差异很大reghdfe ln_wage tenure ttl_exp, a(idcode year) vce(cl idcode), if gvar == 0reghdfe ln_wage tenure ttl_exp, a(idcode year) vce(cl idcode), if gvar == 1 5 非平衡面板下，按照每个样本的第一年分组123456789gen temp = agebys idcode: gen order_num = _ngen temp_in_1 = temp if order_num == 1bys idcode: egen tempall = min(temp_in_1)egen med = median(tempall)gen gvar = (tempall &gt;= med) if !mi(tempall)reghdfe ln_wage tenure ttl_exp, a(idcode year) vce(cl idcode), if gvar == 0reghdfe ln_wage tenure ttl_exp, a(idcode year) vce(cl idcode), if gvar == 1 6 全样本分三组（多组），取高低两组对比1234567xtile gvar = age, nq(3)drop if gvar == 2replace gvar = 0 if gvar == 1replace gvar = 1 if gvar == 3reghdfe ln_wage tenure ttl_exp, a(idcode year) vce(cl idcode), if gvar == 0reghdfe ln_wage tenure ttl_exp, a(idcode year) vce(cl idcode), if gvar == 1 7 逐年份将样本分为三组，取高低两组对比12345678910111213141516* 方法一：runbycap program drop myxtileprogram define myxtile xtile gvar = age, nq(3)endrunby myxtile, by(year) verbose* 方法二：egenmorebys year: egen gvar = xtile(age), n(3)drop if gvar == 2replace gvar = 0 if gvar == 1replace gvar = 1 if gvar == 3reghdfe ln_wage tenure ttl_exp, a(idcode year) vce(cl idcode), if gvar == 0reghdfe ln_wage tenure ttl_exp, a(idcode year) vce(cl idcode), if gvar == 1 8 逐行业-年份将样本分为三组，取高低两组对比12345678910111213141516* 方法一：runbycap program drop myxtileprogram define myxtile xtile gvar = age, nq(3)endrunby myxtile, by(ind_code year) verbose* 方法二：egenmorebys ind_code year: egen gvar = xtile(age), n(3)drop if gvar == 2replace gvar = 0 if gvar == 1replace gvar = 1 if gvar == 3reghdfe ln_wage tenure ttl_exp, a(idcode year) vce(cl idcode), if gvar == 0reghdfe ln_wage tenure ttl_exp, a(idcode year) vce(cl idcode), if gvar == 1 9 系数差异检验后面就是系数差异检验尽情发挥了 chowtest bdiff","link":"/2024/01/09/6-%E5%90%84%E7%A7%8D%E5%88%86%E7%BB%84%E5%9B%9E%E5%BD%92%E6%96%B9%E6%B3%95/"},{"title":"向前与滞后符号技巧","text":"这篇文章简单介绍了下 Stata 滞后符号 L. 与向前符号 F. 的使用小技巧，以滞后符号 L. 为例，F. 类似 1 滞后一期123456webuse nlsworkxtset idcode yearsort idcode yearreg ln_wage L.age 2 滞后两期（多期）123456webuse nlsworkxtset idcode yearsort idcode yearreg ln_wage L2.age 3 滞后一到四期123456webuse nlsworkxtset idcode yearsort idcode yearreg ln_wage L(1/4).age 4 滞后一、三、五期123456webuse nlsworkxtset idcode yearsort idcode yearreg ln_wage L(1 3 5).age 5 交互项 + 滞后一期c. 表示声明变量为连续变量，与 i. 相对 # 表示生成交互项，##表示生成交互项以及各自的单独项 123456webuse nlsworkxtset idcode yearsort idcode yearreg ln_wage c.L.age##c.race 6 差分 + 滞后一期D. 表示一阶向后差分，D.x 表示 123456webuse nlsworkxtset idcode yearsort idcode yearreg ln_wage D.L.age 7 同时几个变量一起滞后123456webuse nlsworkxtset idcode yearsort idcode yearreg ln_wage L(1/4).(age hours tenure)","link":"/2024/01/01/7-%E5%90%91%E5%89%8D%E4%B8%8E%E6%BB%9E%E5%90%8E%E7%AC%A6%E5%8F%B7%E6%8A%80%E5%B7%A7/"},{"title":"公司金融常用Stata代码","text":"使用 Stata 做实证已经有一段时间了，分享一些比较常用的命令，应该大部分的公司金融或者家庭金融论文都能够用到。本人是做公司金融的，所以大部分代码都是和公司研究方面相关的。如有不足，还望补充。 写在前面后文中采用的模型均为双向固定效应模型，固定了个体和年份$$Y = \\alpha + \\beta X + \\eta’Controls + \\delta_i + \\lambda_t + \\varepsilon_{it}$$$Controls$ 是一系列的控制变量 1 数据预处理部分（1）剔除样本通常我们在论文模型部分会看到剔除金融业企业、剔除单一观测值、剔除主要变量缺失的样本，有时还需要剔除部分年份的样本。 12345678910111213141516171819202122232425262728293031323334* 1 剔除金融业drop if industry == &quot;J&quot;// 有时候我们得到的是证监会分类的三位数代码，比如 J70，这时候就需要提取首字母drop if substr(industry, 1, 1) == &quot;J&quot;* 2 剔除样本中的 B 股// 这个可能是经常被忽略的，尽管在正文部分已经提及了使用的是 A 股样本，但是有时候数据中却还包含 B 股样本// stkcd 表示股票代码，注意处理成数值型变量而不是字符型drop if (stkcd &gt;= 200000 &amp; stkcd &lt; 300000)drop if stkcd &gt;= 900000* 3 剔除样本中的 ST、SST等股票// 这个应该是比较常用的操作了，因为股票如果变成 ST，它的名字前面会加上对应的字符drop if substr(name, 1, 3) == &quot;*ST&quot;drop if substr(name, 1, 3) == &quot;SST&quot;drop if substr(name, 1, 2) == &quot;ST&quot;drop if substr(name, 1, 2) == &quot;PT&quot;* 4 剔除主要变量缺失的样本// 这个建议在合并数据后再进行操作// 主要思路是，把所有的变量假装用来回归，然后直接剔除掉没用上的样本就行了global all_vars = &quot;Y X $controls&quot; // $controls 是一系列的控制变量，这里用了 Stata 的全局暂元方法qui reg $all_varskeep if e(sample)* 5 剔除单一观测值// 这个主要用在固定效应中bysort stkcd: gen single = _Ndrop if single &lt;= 1drop single （2）合并数据123456789101112131415* 1 1:1 匹配// 如果主文件（master）和导入文件（using）是通过股票代码和年份一一对应的，那么就采用如下的合并数据方法merge 1:1 stkcd year using &quot;control1.dta&quot;keep if _m == 3drop _m// 需要注意的是，如果在后文中没有使用该导入的数据，那么不建议使用 &quot;keep if _m == 3&quot;，因为这会导致样本损失// 建议使用 &quot;drop if _m == 2&quot; 这样可以尽可能地保留原始样本* 2 m:1 匹配// 如果主文件（master）和导入文件（using）不是一一对应的。例如，导入文件是以城市和年份为唯一标识的。// 由于一个城市有多家企业，所以主文件的多个样本对应了导入文件的一个样本，这个时候就需要 m:1 匹配merge m:1 city year using &quot;control2.dta&quot;keep if _m == 3drop _m （3）常见的公司金融变量生成123456789101112131415// 企业规模gen Size = ln(assets)// 资产负债率（杠杆率）gen Leverage = debts / assets// 资产回报率gen ROA = 2 * net_return / (L.assets + assets)// 企业现金流gen Cashflow = cash / assets// 企业年龄// 有时候会采用成立时间而不是IPO时间gen FirmAge = year - ipo_year 当然，如果做的是 DID 的话，可以采用如下的生成方式 1234567891011121314151617181920* 1 单期 DIDlocal treat_province2010 = &quot;广东省, 广西壮族自治区, 上海市, 北京市, 山西省&quot; // 随便打打inlist2 province, values(`treat_province2010') name(Treat) // inlist2 需要外部安装replace Treat = 0 if Treat == .gen Post = (year &gt;= 2010)gen DID = Treat * Post* 2 多期 DID// 假设有三期，分别是local treat_province2010 = &quot;广东省, 广西壮族自治区, 上海市, 北京市, 山西省&quot; // 随便打打local treat_province2012 = &quot;重庆市, 山东省, 西藏自治区&quot; // 随便打打local treat_province2015 = &quot;江西省, 福建省, 湖南省, 河北省&quot; // 随便打打inlist2 province, values(`treat_province2010') name(Treat2010) // inlist2 需要外部安装inlist2 province, values(`treat_province2012') name(Treat2012)inlist2 province, values(`treat_province2015') name(Treat2015)replace Treat2010 = 0 if Treat2010 == .replace Treat2012 = 0 if Treat2012 == .replace Treat2015 = 0 if Treat2015 == .gen DID = ((Treat2010 == 1) &amp; (year &gt;= 2010)) | ((Treat2012 == 1) &amp; (year &gt;= 2012)) | ((Treat2015 == 1) &amp; (year &gt;= 2015)) （4） 缩尾处理123// 通常需要对连续变量进行 1% 和 99% 处的缩尾处理// 建议直接 replace，不要生成新的变量，容易选错。。。winsor2 $continuous_variables, cut(1, 99) replace （5）在基准回归前在基准回归前，最好是对一些变量设定暂元，方便后续使用。然后把处理好的数据稳健保存好，以免后续处理不小心剔除了某些样本又要重来。 123456* 定义全局暂元global controls = &quot;control1 control2 control3 control4 control5 control6&quot;global independents = &quot;X $controls&quot;* 保存数据文件save &quot;main.dta&quot;, replace 2 描述性统计这部分内容其实没啥好说的。。。代码照抄就是了，/// 表示续行符 123sum2docx Y $independents /// using &quot;描述性统计.docx&quot;, replace /// stats(N mean(%12.3f) sd(%12.3f) min(%12.3f) median(%12.3f) max(%12.3f)) 3 基准回归123456789101112131415161718use &quot;main.dta&quot;, replace // 这里开始就可以体现前面保存数据的好处了// 不放控制变量和固定效应reghdfe Y X , vce(cluster stkcd) // 个体层面的聚类稳健标准误est store m1// 加入控制变量reghdfe Y $independents ,vce(cluster stkcd)est store m2// 加入固定效应reghdfe Y $independents , absorb(stkcd year) vce(cluster stkcd)est store m3// 表格输出reg2docx m1 m2 m3 using &quot;基准回归.docx&quot;, replace /// scalars(N(%20.0fc) r2_a(%9.3f)) b(%9.4f) t(%7.3f) /// addfe(&quot;Firm=YES YES YES&quot; &quot;Year=YES YES YES&quot;) /// mtitles(&quot;OLS&quot; &quot;OLS&quot; &quot;OLS&quot;) /// font(&quot;Times New Roman&quot;, 9) 如果采用的是交乘的方法可以使用 # 符号，c. 声明变量是连续的 1234// 只有交乘项reghdfe Y c.X#c.D $controls , absorb(stkcd year) vce(cluster stkcd)// 包含单独项reghdfe Y c.X##c.D $controls , absorb(stkcd year) vce(cluster stkcd) 4 分组回归和系数差异检验分组回归的方法常用于异质性分析，但由于近年来中介效应模型备受批评，所以也有越来越多的学者采用分组或交乘的方式来做机制检验，因此掌握分组回归和系数差异检验的方法非常重要。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293* 1 按照已有的 0-1 虚拟变量分组，例如“是否国企”// 非国企reghdfe Y $independents , absorb(stkcd year) vce(cluster stkcd), if SOE == 0est store m1// 国企reghdfe Y $independents , absorb(stkcd year) vce(cluster stkcd), if SOE == 1est store m2// 表格输出reg2docx m1 m2 using &quot;国企分组回归.docx&quot;, replace /// scalars(N(%20.0fc) r2_a(%9.3f)) b(%9.4f) t(%7.3f) /// addfe(&quot;Firm=YES YES&quot; &quot;Year=YES YES&quot;) /// mtitles(&quot;Non-SOEs&quot; &quot;SOEs&quot;) /// font(&quot;Times New Roman&quot;, 9)// 系数差异检验// （1）chowtest，其实就是引入交乘项，看交乘项的系数方向对不对，显不显著就行了reghdfe Y c.X##c.SOE $controls , absorb(stkcd year) vce(cluster stkcd)// （2）似无相关模型SUR的检验// 这个貌似不能用 reghdfe，所以还是算了。。。// （3）bdiff// 这个是我常用的命令，详细使用方法可以看连玉君老师的推文bdiff, group(SOE) model(reghdfe Y $independents , absorb(stkcd year) vce(cluster stkcd)) /// reps(1000) bdec(4) pdec(4) bsample seed(123456)* 2 按照中位数分组// 如果是需要按照某个连续变量的中位数进行分组，那么就需要采用一些小小的处理方法qui sum C, detailgen dC = (C &gt;= r(p50)) if !missing(C)// 这里的 dC 就是计算出来的基于中位数的分组变量// 低于中位数的组别reghdfe Y $independents , absorb(stkcd year) vce(cluster stkcd), if dC == 0est store m1// 高于中位数的组别reghdfe Y $independents , absorb(stkcd year) vce(cluster stkcd), if dC == 1est store m2// 表格输出reg2docx m1 m2 using &quot;国企分组回归.docx&quot;, replace /// scalars(N(%20.0fc) r2_a(%9.3f)) b(%9.4f) t(%7.3f) /// addfe(&quot;Firm=YES YES&quot; &quot;Year=YES YES&quot;) /// mtitles(&quot;Low&quot; &quot;High&quot;) /// font(&quot;Times New Roman&quot;, 9)// 系数差异检验bdiff, group(dC) model(reghdfe Y $independents , absorb(stkcd year) vce(cluster stkcd)) /// reps(1000) bdec(4) pdec(4) bsample seed(123456)* 3 按照分位数分组// 有时候中位数分组不显著（就是这么直接），一些作者会采用极端的分组方法。// 例如，最低的 1/3 定为 0，最高的 1/3 定为 1，中间的 1/3 剔除xtile dC = C, nq(3)drop if dC == 2replace dC = 0 if dC == 1replace dC = 1 if dC == 3// 后面就和前面类似了* 4 按照某个连续变量在某一年的中位数进行分组// 这种分类方式其实还是比较少见的。。。大家为了显著都不容易啊。。。// 例如现在有 2008-2020 的上市公司数据，按照变量 C 在 2015 年的中位数分组// 按照哪一年其实也是有讲究的，如果做的是 DID，一般选取事件的前一年// 思路就是把 2015 年的数据填充到其他年份，然后再找中位数分组gen dc = Cgen temp = dc if year == 2015bys code: egen gvar_in_year = min(temp)egen gvar_in_year_median = median(gvar_in_year)gen dC = (gvar_in_year &gt; gvar_in_year_median) if !mi(gvar_in_year)drop dc temp gvar_in_year gvar_in_year_median* 更建议先在原始文件里先处理成指定年份再 merge，然后直接用全样本中位数即可* 不建议先在原始文件里分组再 merge，可能会导致两组样本差异很大* 5 按照是否高于同年/行业/城市/省份中位数进行分组// 这个相对前一个来说简单一些，按行业分别找中位数然后再用变量跟它对比就好bysort industry: egen temp = median(C) // 行业中位数gen dC = (C &gt;= temp) if !missing(temp)drop tempbysort year: egen temp = median(C) // 年份中位数gen dC = (C &gt;= temp) if !missing(temp)drop temp* 6 按照是否高于同年行业/城市/省份中位数进行分组// 这种分组方式感觉怪怪的其实。。。不建议使用bysort industry year: egen temp = median(C)gen dC = (C &gt;= r(p50)) if !missing(temp)drop temp 5 稳健性检验这部分内容建议去看下知乎上专门的文章，我这里就抛砖引玉，主要是介绍下有哪些稳健性检验方法。。。 （1）平行趋势检验DID 必备检验之一，继续沿用前面的 DID 例子。如果大家感兴趣的话，之后可能会专门出一期怎么调平行趋势的文章。。。 12345678910111213141516171819202122232425262728293031323334353637383940// 假设有三期，分别是local treat_province2010 = &quot;广东省, 广西壮族自治区, 上海市, 北京市, 山西省&quot; // 随便打打local treat_province2012 = &quot;重庆市, 山东省, 西藏自治区&quot; // 随便打打local treat_province2015 = &quot;江西省, 福建省, 湖南省, 河北省&quot; // 随便打打inlist2 province, values(`treat_province2010') name(Treat2010) // inlist2 需要外部安装inlist2 province, values(`treat_province2012') name(Treat2012)inlist2 province, values(`treat_province2015') name(Treat2015)gen current = ((Treat2010 == 1) &amp; (year == 2010)) | ((Treat2012 == 1) &amp; (year == 2012)) | ((Treat2015 == 1) &amp; (year == 2015))gen Treat_Year = year if current == 1bysort stkcd: egen Treat_Year2 = sum(Treat_Year)drop Treat_Yearrename Treat_Year2 Treat_Yearforvalue i = 4(-1)2{ gen Before`i'_ = cond(year - Treat_Year &lt;= -`i' &amp; Treat_Year != ., 1, 0)}forvalue i = 4(-1)1{ gen Before`i' = cond(year - Treat_Year == -`i', 1, 0)}forvalue i = 0(1)5{ gen After`i' = cond(year - Treat_Year == `i', 1, 0)}forvalue i = 2(1)5{ gen After`i'_ = cond(year - Treat_Year &gt;= `i' &amp; Treat_Year != ., 1, 0)}reghdfe Y Before3_ Before2 Before1 After0 After1 After2 After3_ $controls , absorb(stkcd year) vce(cluster stkcd)est store m1coefplot m1, keep(Before3_ Before2 Before1 After0 After1 After2 After3_) /// levels(95) /// vertical yline(0) xline(4, lp(dash)) /// xtitle(&quot;period&quot;) ytitle(&quot;coefficient&quot;) /// addplot(line @b @at) ciopts(lpattern(dash) /// recast(rcap) msize(medium)) /// msymbol(circle_hollow) /// scheme(s1mono) （2）安慰剂检验这个也是 DID 必备的检验之一，通常可以分为对 $Treat$ 随机、对 $Post$ 随机和对 $DID$ 随机。这里我以单期 $DID$ 对 $Treat$ 随机为例子。（多期 DID 好像只能对 DID 随机） 12345678local treat_province2010 = &quot;广东省, 广西壮族自治区, 上海市, 北京市, 山西省&quot; // 随便打打inlist2 province, values(`treat_province2010') name(Treat) // inlist2 需要外部安装replace Treat = 0 if Treat == .gen Post = (year &gt;= 2010)permute Treat beta = _b[c.Treat#c.Post] t = (_b[c.Treat#c.Post] / _se[c.Treat#c.Post]), /// reps(1000) rseed(123456) saving(&quot;simulations.dta&quot;, replace): /// reghdfe Y c.Treat#c.Post $controls , absorb(stkcd year) vce(cluster stkcd) “beta = _b[c.Treat#c.Post] t = (_b[c.Treat#c.Post] / _se[c.Treat#c.Post])” 表示分别将交互项的系数和 t 值记录下来，然后再对输出文件 simulations.dta 做描述性统计就可以得到安慰剂检验的结果。当然，也可以直接查看 permute 的输出结果，可以参考我的另一篇文章。 （3）工具变量法工具变量法采用 ivreghdfe 命令，该命令还可以输出一系列的弱工具变量检验结果。当然要注意的是这个命令没办法使用稳健标准误。 1ivreghdfe Y (X = IV) $controls , absorb(stkcd year) 还有另一种方法是通过手动 2SLS 回归，这种方法还能够分别输出两阶段的回归结果，所以更加推荐使用。 123reghdfe X IV $controls , absorb(stkcd year) vce(cluster stkcd)predict X_hatreghdfe Y X_hat $controls , absorb(stkcd year) vce(cluster stkcd) 如果一阶段 F 值大于经验值 10，通常就可以认为不存在弱工具变量问题了。但是其他的弱工具变量检验就需要自己去操作了。 （4）遗漏变量问题遗漏变量也是内生性的一种来源，而且近几年的文献越来越关注遗漏变量可能导致的后门路径问题。一般分为两种解决方法。 第一种是增加更多的控制变量以控制遗漏混淆变量影响。比如加入更多的固定效应，其他层面的控制变量等等。 第二种是证明遗漏变量对原文结论没有很大影响，常见的方法有 Oster 检验（2019）和 Frank（2000）提出的 Konfound 检验。Oster检验可以见我前面提到的那篇文章，Frank（2000）的方法可以看下连玉君老师的推文。 https://www.lianxh.cn/news/576be9d47ceeb.html https://zhuanlan.zhihu.com/p/513830106 https://www.lianxh.cn/news/4832e3735dc81.html 6 总结以上便是一些常见的实证论文中的 Stata 操作，当然难免会有遗漏。如有问题还希望大家指出，一起进步。","link":"/2023/01/06/4-%E5%85%AC%E5%8F%B8%E9%87%91%E8%9E%8D%E5%B8%B8%E7%94%A8Stata%E4%BB%A3%E7%A0%81/"},{"title":"Permutation test 和 Oster test 的 Stata 实现","text":"置换检验和 Oster test 的 Stata 实现 后文用的模型均为：$$y_{it} = \\beta_0 + \\beta_1x_{it}+\\beta’ controls_{it} + \\mu_i + \\lambda_t + \\epsilon_{it}$$内生性问题主要包括遗漏变量、反向因果还有选择性偏误，第一个问题可以通过增加更多变量解决，比如引入其他层面的固定效应，第二个反向因果问题可以通过工具变量法等方法解决，第三个选择性偏差包括样本选择偏误和自选择偏误，前者可以通过 PSM-DID 等方法解决，后者可以通过Heckman 2sls 等方法解决。本文介绍的Permutation test 和 Oster test 是从另外一个视角去探讨遗漏变量内生性问题，尤其是在找不到工具变量和遗漏变量不可观测、不可分离的时候较为有效。 1 Permutation test / Randomization test / 置换检验 排除共存事件的影响，比如在做 DID 的时候，有些其他事件冲击可能与我们所关心的事件是同时发生的，通过置换检验一定程度上可以排除这些共存事件的干扰。 1reg y x age size soe i.industry i.year, r 接下来的是对 $x$ 进行 permute 500 次【命令中的 permute x 和 option 里面的 reps(500) 】，每次都是对同一家公司不同年份进行 permute 【option 里面的 strata(code)】，这样就不会把 A 公司的数据给了 B 公司（不然就搞得和安慰剂检验差不多了）。最终的目的是对 x 的系数进行估计【命令中的 beta=_b[x] ，意思就是把 x 的系数赋值给 beta 这个变量名，其实改成别的或者不加也行】，冒号后面是基准模型。 1permute x beta=_b[x], reps(500) strata(code):reg y x age size soe, r 图中的 -0.0066581 就是前面基准回归的系数，由于这个系数是负的，所以我们看看这 500 次里面有多少次是比这个系数更负，也就是 lower 后面那个数字 0 ，意思就是 500 次 permute 的结果，$x$ 的系数全都大于 -0.0066581，经验 $p$ 值为后面的 0.0000（计算方法是 p = c / n），说明我们的结果是稳健的，不太可能有共存的事件影响我们的估计结果。 tips：如果原本的系数是正的就看下面的 upper 那行 此外，如果做的是 DID 的话，比如方程是$$y_{it} = \\beta_0 + \\beta_1treat_{i}\\times post_t+\\beta’ controls_{it} + \\mu_i + \\lambda_t + \\epsilon_{it}$$那就可以把命令改成对 $treat$ 进行 permute， 1permute treat beta=_b[c.treat#c.post], reps(500) strata(code):reg y c.treat#c.post age size soe i.industry i.year, r 经验 $p$ 值 0.3080 （154 / 500），500 次 permutation 里面就有 154 次比 -0.0268812 要小，所以置换检验没有通过，共存事件的影响不可忽视。 2 Oster test（2019） 其实这个检验目前还没有明确的名字，我姑且叫它 Oster test 吧。这个检验是用来检验遗漏变量的影响，比如，未观测到的因素需要比已观测到的因素作用大多少才能够对原估计结果产生显著影响（使 β = 0 或者 β 逆转为正数[前面提到的结果是负数]），所以这个办法本质上就是用来说明遗漏变量不会影响我们的主要结果。 2.1 是否存在和已经观测到的变量同等重要的未观测到的变量对我们的估计结果产生影响？ 更新：建议使用 github 上提供的 psacalc2，支持 reghdfe 命令后果运行，使用方法不变 链接 ==&gt; psacalc with support for reghdfe Oster test 分为两个部分，首先第一个部分是用来检验是否存在和已经观测到的变量（包括固定效应）同等重要的未观测到的变量对我们的估计结果产生影响？ 按照 Oster 原文以及一些顶刊的做法，通过 $R^2$ 和 $\\delta$ 对“真实的” $\\beta$ 区间（true $\\beta$）进行复原。首先给出两个假设， 引入未观测到的因素后 $R^2$ 会变为原来 1.3 倍（这个 1.3 是 Oster 的建议值）； 未观测到的变量对被解释变量的影响和已观测到的变量（包括固定效应）的影响至少相同（即 $\\delta = 1$ ，也是个建议值） 用到的 Stata 包是 psacalc，执行的命令为 123reg y x age big4 dual assets debts top institude soe, r level(99.5) // 置信区间设为 99.5% ，后面有用global r = e(r2) * 1.3 // 设为 1.3 倍psacalc beta x, delta(1) rmax($r) 首先是回归结果，记住这个 99.5 % 置信区间 [-0.0092741, -0.0052753]， psacalc beta 的输出结果如下， 没有引入控制变量和固定效应前，回归系数为 -0.00727 ，对应的 $R^2$ 为 0.004，控制后分别变为 -0.007270（没变，好家伙，为了区分多加个 0） 和 0.009，上面有个 beta 值为 -0.00728， 那么上面汇报的 beta 值与控制后的系数组成了“真实的” $\\beta$ 区间 [-0.00728, -0.007270]，该区间不包含 0 值，且落于前面提到的 99.5% 置信区间 [-0.0092741, -0.0052753] 内。这个结果说明了不太可能与已经观测到的变量（包括固定效应）同等重要的未观测到的变量对我们的结果产生显著影响。（使得 $\\beta$ 失效等于 0 或令其逆转为正） 2.2 未观测到的变量至少要产生多少倍于已经观测到的变量的影响才能够使得 β = 0？第二个检验换了一个角度去思考，假设 引入未观测到的因素后 $R^2$ 会变为原来 1.3 倍（这个 1.3 是 Oster 的建议值）； $\\beta = 0$ 执行的命令为 1psacalc delta x, beta(0) rmax($r) 结果输出如下， 可以发现上面的 delta 值为 24.20817 ，也就是说，未观测到的变量产生的影响至少24倍于已经观测到的变量才能够使得 β = 0，该结果表明不太可能存在未观测到的变量对我们的结果产生显著影响。（存在24倍影响的未观测变量是不太可能的） 根据知乎评论区朋友提供的资料，下面这个链接认为 delta 小于 0 时，只要小于 -1 也是可以的。 ==&gt; 知乎文章 我在其他的论文中发现 delta 其实小于 0 都是可以的，说明加入遗漏变量后，系数会更偏向于基准的方向。 3 怎么汇报结果？那么 Oster test 的结果应该如何汇报呢？我找了下文献，看到有这两种汇报方法， Donohoe, M.P., Jang, H. and Lisowsky, P., 2022. Competitive externalities of tax cuts. Journal of Accounting Research, 60(1), pp.201-259. Aubery, F. and Sahn, D.E., 2021. Cognitive achievement production in Madagascar: a value-added model approach. Education Economics, 29(6), pp.670-699. 顺带加个置换检验的展示图， Donohoe, M.P., Jang, H. and Lisowsky, P., 2022. Competitive externalities of tax cuts. Journal of Accounting Research, 60(1), pp.201-259. 如有不对还请指出！ 4 参考资料 Aubery, F. and Sahn, D.E., 2021. Cognitive achievement production in Madagascar: a value-added model approach. Education Economics, 29(6), pp.670-699. Donohoe, M.P., Jang, H. and Lisowsky, P., 2022. Competitive externalities of tax cuts. Journal of Accounting Research, 60(1), pp.201-259. Oster, E., 2019. Unobservable selection and coefficient stability: Theory and evidence. Journal of Business & Economic Statistics, 37(2), pp.187-204. 无工具变量解决遗漏变量内生性问题的psacalc方法及stata命令 - 经管代码库 - 经管之家(原人大经济论坛) https://bbs.pinggu.org/thread-10977856-1-1.html 前沿: 解决内生性问题的无工具变量推断法 https://mp.weixin.qq.com/s/o9bqdOSkqwsV_9QSrl_OUA 什么是经济学中的自选择问题？https://www.zhihu.com/question/311199969","link":"/2022/05/13/5-permutation_oster/"}],"tags":[{"name":"数学","slug":"数学","link":"/tags/%E6%95%B0%E5%AD%A6/"},{"name":"Stata","slug":"Stata","link":"/tags/Stata/"},{"name":"计量经济学","slug":"计量经济学","link":"/tags/%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A6/"},{"name":"金融学","slug":"金融学","link":"/tags/%E9%87%91%E8%9E%8D%E5%AD%A6/"},{"name":"考博","slug":"考博","link":"/tags/%E8%80%83%E5%8D%9A/"},{"name":"统计学","slug":"统计学","link":"/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6/"},{"name":"AI","slug":"AI","link":"/tags/AI/"},{"name":"Prompt","slug":"Prompt","link":"/tags/Prompt/"},{"name":"SAS","slug":"SAS","link":"/tags/SAS/"},{"name":"WRDS","slug":"WRDS","link":"/tags/WRDS/"}],"categories":[{"name":"编程学习","slug":"编程学习","link":"/categories/%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"金融学","slug":"金融学","link":"/categories/%E9%87%91%E8%9E%8D%E5%AD%A6/"},{"name":"统计学","slug":"统计学","link":"/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6/"},{"name":"AI","slug":"AI","link":"/categories/AI/"},{"name":"公司金融","slug":"公司金融","link":"/categories/%E5%85%AC%E5%8F%B8%E9%87%91%E8%9E%8D/"}],"pages":[{"title":"","text":"⭐关于我⭐个人介绍 📝经管类在读研究生 💻擅长Python、Stata等编程语言 🌏精通爬虫、计量分析、自然语言处理等技能 🍟爱吃垃圾食品 🧋快乐肥宅 社交媒体 📮邮箱：codefox2020@163.com 💡知乎主页：https://www.zhihu.com/people/Keynes 🌐GitHub 主页：https://codefoxs.github.io","link":"/about.html"}]}